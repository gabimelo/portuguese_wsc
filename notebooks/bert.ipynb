{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('..')\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0128 00:28:57.202524 140120516495104 file_utils.py:35] PyTorch version 1.0.1.post2 available.\n",
      "W0128 00:28:57.979238 140120516495104 __init__.py:28] To use data.metrics please install scikit-learn. See https://scikit-learn.org/stable/index.html\n"
     ]
    }
   ],
   "source": [
    "from functools import partial\n",
    "\n",
    "import torch\n",
    "from transformers import BertTokenizer, BertForNextSentencePrediction\n",
    "\n",
    "\n",
    "def get_probability_of_next_sentence(tokenizer, model, text1, text2):\n",
    "    text1_toks = [\"[CLS]\"] + tokenizer.tokenize(text1) + [\"[SEP]\"]\n",
    "    text2_toks = tokenizer.tokenize(text2) + [\"[SEP]\"]\n",
    "    text = text1_toks+text2_toks\n",
    "    indexed_tokens = tokenizer.convert_tokens_to_ids(text)\n",
    "    segments_ids = [0]*len(text1_toks) + [1]*len(text2_toks)\n",
    "\n",
    "    tokens_tensor = torch.tensor([indexed_tokens])\n",
    "    segments_tensors = torch.tensor([segments_ids])\n",
    "\n",
    "    model.eval()\n",
    "    prediction = model(tokens_tensor, token_type_ids=segments_tensors)\n",
    "    prediction=prediction[0] # tuple to tensor\n",
    "    softmax = torch.nn.Softmax(dim=1)\n",
    "    prediction_sm = softmax(prediction)\n",
    "\n",
    "    return prediction_sm[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0128 00:28:58.603835 140120516495104 tokenization_utils.py:398] loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/gabrielamelo/.cache/torch/transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n",
      "I0128 00:28:59.222384 140120516495104 configuration_utils.py:185] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /home/gabrielamelo/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.bf3b9ea126d8c0001ee8a1e8b92229871d06d36d8808208cc2449280da87785c\n",
      "I0128 00:28:59.224655 140120516495104 configuration_utils.py:199] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "I0128 00:28:59.811100 140120516495104 modeling_utils.py:406] loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-pytorch_model.bin from cache at /home/gabrielamelo/.cache/torch/transformers/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n",
      "I0128 00:29:01.932347 140120516495104 modeling_utils.py:483] Weights from pretrained model not used in BertForNextSentencePrediction: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertForNextSentencePrediction.from_pretrained('bert-base-uncased')\n",
    "\n",
    "partial_get_probability_of_next_sentence = partial(get_probability_of_next_sentence, tokenizer, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([4.1673e-04, 9.9958e-01], grad_fn=<SelectBackward>)\n"
     ]
    }
   ],
   "source": [
    "text1 = \"How old are you?\"\n",
    "text2 = \"The Eiffel Tower is in Paris\"\n",
    "prediction = partial_get_probability_of_next_sentence(text1, text2)\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([9.9999e-01, 9.6342e-06], grad_fn=<SelectBackward>)\n",
      "tensor(1.0000, grad_fn=<SelectBackward>)\n"
     ]
    }
   ],
   "source": [
    "text1 = \"How old are you?\"\n",
    "text2 = \"I am 22 years old\"\n",
    "prediction = partial_get_probability_of_next_sentence(text1, text2)\n",
    "print(prediction)\n",
    "print(prediction[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0128 00:29:02.621064 140120516495104 tokenization_utils.py:398] loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-multilingual-cased-vocab.txt from cache at /home/gabrielamelo/.cache/torch/transformers/96435fa287fbf7e469185f1062386e05a075cadbf6838b74da22bf64b080bc32.99bcd55fc66f4f3360bc49ba472b940b8dcf223ea6a345deb969d607ca900729\n",
      "I0128 00:29:03.348755 140120516495104 configuration_utils.py:185] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-multilingual-cased-config.json from cache at /home/gabrielamelo/.cache/torch/transformers/45629519f3117b89d89fd9c740073d8e4c1f0a70f9842476185100a8afe715d1.83b0fa3d7f1ac0e113ad300189a938c6f14d0588a4200f30eef109d0a047c484\n",
      "I0128 00:29:03.349600 140120516495104 configuration_utils.py:199] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 119547\n",
      "}\n",
      "\n",
      "I0128 00:29:03.907659 140120516495104 modeling_utils.py:406] loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-multilingual-cased-pytorch_model.bin from cache at /home/gabrielamelo/.cache/torch/transformers/5b5b80054cd2c95a946a8e0ce0b93f56326dff9fbda6a6c3e02de3c91c918342.7131dcb754361639a7d5526985f880879c9bfd144b65a0bf50590bddb7de9059\n",
      "I0128 00:29:07.228557 140120516495104 modeling_utils.py:483] Weights from pretrained model not used in BertForNextSentencePrediction: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased')\n",
    "model = BertForNextSentencePrediction.from_pretrained('bert-base-multilingual-cased')\n",
    "\n",
    "partial_get_probability_of_next_sentence = partial(get_probability_of_next_sentence, tokenizer, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.8567, 0.1433], grad_fn=<SelectBackward>)\n"
     ]
    }
   ],
   "source": [
    "text1 = \"Quantos anos você tem?\"\n",
    "text2 = \"A Torre Eiffel fica em Paris\"\n",
    "prediction = partial_get_probability_of_next_sentence(text1, text2)\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.9411, 0.0589], grad_fn=<SelectBackward>)\n"
     ]
    }
   ],
   "source": [
    "text1 = \"Quantos anos você tem?\"\n",
    "text2 = \"Eu tenho 22 anos\"\n",
    "prediction = partial_get_probability_of_next_sentence(text1, text2)\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentence_breaks(first_sentence, second_sentence):\n",
    "    for i in range(len(first_sentence.split())):\n",
    "        if first_sentence.split()[i] != second_sentence.split()[i]:  # noqaE226\n",
    "            break\n",
    "    return i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_get_sentence_breaks():\n",
    "    first_sentence = 'The city councilmen refused the demonstrators a permit because the city councilmen feared violence.'\n",
    "    second_sentence = 'The city councilmen refused the demonstrators a permit because the demonstrators feared violence.'\n",
    "    i = get_sentence_breaks(first_sentence, second_sentence)\n",
    "    assert ' '.join(first_sentence.split()[:i]) == \\\n",
    "        'The city councilmen refused the demonstrators a permit because the'\n",
    "    assert ' '.join(second_sentence.split()[:i]) == \\\n",
    "        'The city councilmen refused the demonstrators a permit because the'\n",
    "    assert ' '.join(first_sentence.split()[i:]) == \\\n",
    "        'city councilmen feared violence.'\n",
    "    assert ' '.join(second_sentence.split()[i:]) == \\\n",
    "        'demonstrators feared violence.'\n",
    "    \n",
    "    first_sentence = 'Os vereadores recusaram a autorização aos manifestantes porque os vereadores temiam a violência.'\n",
    "    second_sentence = 'Os vereadores recusaram a autorização aos manifestantes porque os manifestantes temiam a violência.'\n",
    "    \n",
    "    i = get_sentence_breaks(first_sentence, second_sentence)\n",
    "    assert ' '.join(first_sentence.split()[:i]) == \\\n",
    "        'Os vereadores recusaram a autorização aos manifestantes porque os'\n",
    "    assert ' '.join(second_sentence.split()[:i]) == \\\n",
    "        'Os vereadores recusaram a autorização aos manifestantes porque os'\n",
    "    assert ' '.join(first_sentence.split()[i:]) == \\\n",
    "        'vereadores temiam a violência.'\n",
    "    assert ' '.join(second_sentence.split()[i:]) == \\\n",
    "        'manifestantes temiam a violência.'\n",
    "    \n",
    "test_get_sentence_breaks()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wsc_port",
   "language": "python",
   "name": "wsc_port"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
