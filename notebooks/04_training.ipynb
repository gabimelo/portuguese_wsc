{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('..')\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'src'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-44ef0ea1d895>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconsts\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmain\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msetup_torch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_corpus\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRNNModel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'src'"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "\n",
    "import torch\n",
    "\n",
    "import torch.nn as nn\n",
    "\n",
    "from src.consts import *\n",
    "from src.main import main, setup_torch, get_corpus\n",
    "from src.model import RNNModel\n",
    "from src.training import train, evaluate\n",
    "from src.split_cross_entropy_loss import SplitCrossEntropyLoss\n",
    "from src.utils import summary, check_cuda_mem, get_latest_model_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_data_paralellization = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RNNModel(\n",
      "  (drop): Dropout(p=0.2)\n",
      "  (encoder): Embedding(602755, 200)\n",
      "  (rnn): LSTM(200, 200, num_layers=2, dropout=0.2)\n",
      "  (decoder): Linear(in_features=200, out_features=602755, bias=True)\n",
      ")\n",
      "\n",
      "encoder.weight torch.Size([602755, 200])\n",
      "rnn.weight_ih_l0 torch.Size([800, 200])\n",
      "rnn.weight_hh_l0 torch.Size([800, 200])\n",
      "rnn.bias_ih_l0 torch.Size([800])\n",
      "rnn.bias_hh_l0 torch.Size([800])\n",
      "rnn.weight_ih_l1 torch.Size([800, 200])\n",
      "rnn.weight_hh_l1 torch.Size([800, 200])\n",
      "rnn.bias_ih_l1 torch.Size([800])\n",
      "rnn.bias_hh_l1 torch.Size([800])\n",
      "decoder.weight torch.Size([602755, 200])\n",
      "decoder.bias torch.Size([602755])\n",
      "\n",
      "Total Parameters: 121,796,955\n"
     ]
    }
   ],
   "source": [
    "setup_torch()\n",
    "device = torch.device(\"cuda\" if USE_CUDA else \"cpu\")\n",
    "corpus = get_corpus()\n",
    "\n",
    "# TODO remove these two lines\n",
    "assert len(corpus.dictionary) == 602755\n",
    "assert corpus.valid.size()[0] == 11606861\n",
    "assert corpus.train.max() < len(corpus.dictionary)\n",
    "assert corpus.valid.max() < len(corpus.dictionary)\n",
    "assert corpus.test.max() < len(corpus.dictionary)\n",
    "\n",
    "# code below is not updated, should get updated version on main.py\n",
    "ntokens = len(corpus.dictionary)\n",
    "model = RNNModel(MODEL_TYPE, ntokens, EMBEDDINGS_SIZE, HIDDEN_UNIT_COUNT, LAYER_COUNT, DROPOUT_PROB,\n",
    "                 TIED)\n",
    "if use_data_paralellization or USE_DATA_PARALLELIZATION:\n",
    "    model = CustomDataParallel(model)\n",
    "else:\n",
    "    model.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "summary(model, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO 2019-05-24 17:20:20,605: | epoch   1 |   200/23759 batches | lr 20.00 | ms/batch 168.17 | loss  9.71 | ppl 16518.85\n",
      "INFO 2019-05-24 17:20:54,223: | epoch   1 |   400/23759 batches | lr 20.00 | ms/batch 168.09 | loss  8.27 | ppl  3900.39\n",
      "INFO 2019-05-24 17:21:28,045: | epoch   1 |   600/23759 batches | lr 20.00 | ms/batch 169.11 | loss  7.50 | ppl  1814.86\n",
      "INFO 2019-05-24 17:22:01,898: | epoch   1 |   800/23759 batches | lr 20.00 | ms/batch 169.26 | loss  7.18 | ppl  1311.43\n",
      "INFO 2019-05-24 17:22:35,704: | epoch   1 |  1000/23759 batches | lr 20.00 | ms/batch 169.03 | loss  6.97 | ppl  1066.40\n",
      "INFO 2019-05-24 17:23:09,617: | epoch   1 |  1200/23759 batches | lr 20.00 | ms/batch 169.56 | loss  6.74 | ppl   841.74\n",
      "INFO 2019-05-24 17:23:43,440: | epoch   1 |  1400/23759 batches | lr 20.00 | ms/batch 169.11 | loss  6.60 | ppl   735.89\n",
      "INFO 2019-05-24 17:24:17,229: | epoch   1 |  1600/23759 batches | lr 20.00 | ms/batch 168.94 | loss  6.48 | ppl   653.93\n",
      "INFO 2019-05-24 17:24:51,161: | epoch   1 |  1800/23759 batches | lr 20.00 | ms/batch 169.66 | loss  6.32 | ppl   555.23\n",
      "INFO 2019-05-24 17:25:25,054: | epoch   1 |  2000/23759 batches | lr 20.00 | ms/batch 169.46 | loss  6.09 | ppl   443.26\n",
      "INFO 2019-05-24 17:25:58,956: | epoch   1 |  2200/23759 batches | lr 20.00 | ms/batch 169.51 | loss  6.20 | ppl   490.44\n",
      "INFO 2019-05-24 17:26:32,839: | epoch   1 |  2400/23759 batches | lr 20.00 | ms/batch 169.41 | loss  5.99 | ppl   398.59\n",
      "INFO 2019-05-24 17:27:06,776: | epoch   1 |  2600/23759 batches | lr 20.00 | ms/batch 169.68 | loss  6.17 | ppl   477.43\n",
      "INFO 2019-05-24 17:27:40,669: | epoch   1 |  2800/23759 batches | lr 20.00 | ms/batch 169.46 | loss  6.21 | ppl   495.46\n",
      "INFO 2019-05-24 17:28:14,605: | epoch   1 |  3000/23759 batches | lr 20.00 | ms/batch 169.68 | loss  6.17 | ppl   479.78\n",
      "INFO 2019-05-24 17:28:48,584: | epoch   1 |  3200/23759 batches | lr 20.00 | ms/batch 169.89 | loss  5.96 | ppl   386.81\n",
      "INFO 2019-05-24 17:29:22,514: | epoch   1 |  3400/23759 batches | lr 20.00 | ms/batch 169.65 | loss  5.92 | ppl   371.00\n",
      "INFO 2019-05-24 17:29:56,308: | epoch   1 |  3600/23759 batches | lr 20.00 | ms/batch 168.97 | loss  6.11 | ppl   451.58\n",
      "INFO 2019-05-24 17:30:30,261: | epoch   1 |  3800/23759 batches | lr 20.00 | ms/batch 169.76 | loss  5.97 | ppl   390.43\n",
      "INFO 2019-05-24 17:31:03,990: | epoch   1 |  4000/23759 batches | lr 20.00 | ms/batch 168.65 | loss  6.06 | ppl   428.50\n",
      "INFO 2019-05-24 17:31:37,938: | epoch   1 |  4200/23759 batches | lr 20.00 | ms/batch 169.73 | loss  5.72 | ppl   304.83\n",
      "INFO 2019-05-24 17:32:11,741: | epoch   1 |  4400/23759 batches | lr 20.00 | ms/batch 169.01 | loss  5.96 | ppl   389.41\n",
      "INFO 2019-05-24 17:32:45,499: | epoch   1 |  4600/23759 batches | lr 20.00 | ms/batch 168.79 | loss  5.96 | ppl   387.94\n",
      "INFO 2019-05-24 17:33:19,284: | epoch   1 |  4800/23759 batches | lr 20.00 | ms/batch 168.93 | loss  5.81 | ppl   333.65\n",
      "INFO 2019-05-24 17:33:53,276: | epoch   1 |  5000/23759 batches | lr 20.00 | ms/batch 169.96 | loss  5.73 | ppl   307.01\n",
      "INFO 2019-05-24 17:34:27,181: | epoch   1 |  5200/23759 batches | lr 20.00 | ms/batch 169.52 | loss  5.73 | ppl   307.03\n",
      "INFO 2019-05-24 17:35:01,045: | epoch   1 |  5400/23759 batches | lr 20.00 | ms/batch 169.32 | loss  5.63 | ppl   277.37\n",
      "INFO 2019-05-24 17:35:34,934: | epoch   1 |  5600/23759 batches | lr 20.00 | ms/batch 169.44 | loss  5.75 | ppl   314.07\n",
      "INFO 2019-05-24 17:36:08,829: | epoch   1 |  5800/23759 batches | lr 20.00 | ms/batch 169.47 | loss  5.62 | ppl   274.66\n",
      "INFO 2019-05-24 17:36:42,659: | epoch   1 |  6000/23759 batches | lr 20.00 | ms/batch 169.14 | loss  5.69 | ppl   296.35\n",
      "INFO 2019-05-24 17:37:16,418: | epoch   1 |  6200/23759 batches | lr 20.00 | ms/batch 168.79 | loss  5.74 | ppl   312.45\n",
      "INFO 2019-05-24 17:37:50,201: | epoch   1 |  6400/23759 batches | lr 20.00 | ms/batch 168.91 | loss  5.57 | ppl   262.48\n",
      "INFO 2019-05-24 17:38:23,977: | epoch   1 |  6600/23759 batches | lr 20.00 | ms/batch 168.88 | loss  5.66 | ppl   287.21\n",
      "INFO 2019-05-24 17:38:57,721: | epoch   1 |  6800/23759 batches | lr 20.00 | ms/batch 168.72 | loss  5.60 | ppl   271.28\n",
      "INFO 2019-05-24 17:39:31,500: | epoch   1 |  7000/23759 batches | lr 20.00 | ms/batch 168.89 | loss  5.47 | ppl   238.06\n",
      "INFO 2019-05-24 17:40:05,252: | epoch   1 |  7200/23759 batches | lr 20.00 | ms/batch 168.76 | loss  5.35 | ppl   209.77\n",
      "INFO 2019-05-24 17:40:39,032: | epoch   1 |  7400/23759 batches | lr 20.00 | ms/batch 168.89 | loss  5.25 | ppl   191.47\n",
      "INFO 2019-05-24 17:41:12,910: | epoch   1 |  7600/23759 batches | lr 20.00 | ms/batch 169.39 | loss  5.45 | ppl   232.01\n",
      "INFO 2019-05-24 17:41:46,769: | epoch   1 |  7800/23759 batches | lr 20.00 | ms/batch 169.29 | loss  5.41 | ppl   223.00\n",
      "INFO 2019-05-24 17:42:20,642: | epoch   1 |  8000/23759 batches | lr 20.00 | ms/batch 169.36 | loss  5.46 | ppl   234.49\n",
      "INFO 2019-05-24 17:42:54,448: | epoch   1 |  8200/23759 batches | lr 20.00 | ms/batch 169.03 | loss  5.48 | ppl   240.23\n",
      "INFO 2019-05-24 17:43:28,362: | epoch   1 |  8400/23759 batches | lr 20.00 | ms/batch 169.56 | loss  5.53 | ppl   252.66\n",
      "INFO 2019-05-24 17:44:02,331: | epoch   1 |  8600/23759 batches | lr 20.00 | ms/batch 169.85 | loss  5.44 | ppl   231.12\n",
      "INFO 2019-05-24 17:44:36,236: | epoch   1 |  8800/23759 batches | lr 20.00 | ms/batch 169.52 | loss  5.39 | ppl   220.08\n",
      "INFO 2019-05-24 17:45:10,115: | epoch   1 |  9000/23759 batches | lr 20.00 | ms/batch 169.39 | loss  5.55 | ppl   256.58\n",
      "INFO 2019-05-24 17:45:43,877: | epoch   1 |  9200/23759 batches | lr 20.00 | ms/batch 168.81 | loss  5.56 | ppl   260.46\n",
      "INFO 2019-05-24 17:46:17,605: | epoch   1 |  9400/23759 batches | lr 20.00 | ms/batch 168.64 | loss  5.61 | ppl   272.97\n",
      "INFO 2019-05-24 17:46:51,364: | epoch   1 |  9600/23759 batches | lr 20.00 | ms/batch 168.79 | loss  5.56 | ppl   260.63\n",
      "INFO 2019-05-24 17:47:25,149: | epoch   1 |  9800/23759 batches | lr 20.00 | ms/batch 168.92 | loss  5.40 | ppl   221.08\n",
      "INFO 2019-05-24 17:47:58,821: | epoch   1 | 10000/23759 batches | lr 20.00 | ms/batch 168.36 | loss  5.35 | ppl   211.32\n",
      "INFO 2019-05-24 17:48:32,638: | epoch   1 | 10200/23759 batches | lr 20.00 | ms/batch 169.08 | loss  5.36 | ppl   211.90\n",
      "INFO 2019-05-24 17:49:06,347: | epoch   1 | 10400/23759 batches | lr 20.00 | ms/batch 168.54 | loss  5.23 | ppl   186.25\n",
      "INFO 2019-05-24 17:49:40,163: | epoch   1 | 10600/23759 batches | lr 20.00 | ms/batch 169.08 | loss  5.48 | ppl   238.71\n",
      "INFO 2019-05-24 17:50:13,904: | epoch   1 | 10800/23759 batches | lr 20.00 | ms/batch 168.71 | loss  5.38 | ppl   216.74\n",
      "INFO 2019-05-24 17:50:47,691: | epoch   1 | 11000/23759 batches | lr 20.00 | ms/batch 168.93 | loss  5.35 | ppl   209.83\n",
      "INFO 2019-05-24 17:51:21,377: | epoch   1 | 11200/23759 batches | lr 20.00 | ms/batch 168.42 | loss  5.41 | ppl   223.54\n",
      "INFO 2019-05-24 17:51:55,081: | epoch   1 | 11400/23759 batches | lr 20.00 | ms/batch 168.52 | loss  5.38 | ppl   216.37\n",
      "INFO 2019-05-24 17:52:28,801: | epoch   1 | 11600/23759 batches | lr 20.00 | ms/batch 168.60 | loss  5.38 | ppl   217.03\n",
      "INFO 2019-05-24 17:53:02,482: | epoch   1 | 11800/23759 batches | lr 20.00 | ms/batch 168.41 | loss  5.22 | ppl   184.36\n",
      "INFO 2019-05-24 17:53:36,133: | epoch   1 | 12000/23759 batches | lr 20.00 | ms/batch 168.25 | loss  5.22 | ppl   184.84\n",
      "INFO 2019-05-24 17:54:09,913: | epoch   1 | 12200/23759 batches | lr 20.00 | ms/batch 168.90 | loss  5.35 | ppl   211.54\n",
      "INFO 2019-05-24 17:54:43,628: | epoch   1 | 12400/23759 batches | lr 20.00 | ms/batch 168.57 | loss  5.29 | ppl   197.69\n",
      "INFO 2019-05-24 17:55:17,393: | epoch   1 | 12600/23759 batches | lr 20.00 | ms/batch 168.82 | loss  5.27 | ppl   195.39\n",
      "INFO 2019-05-24 17:55:51,131: | epoch   1 | 12800/23759 batches | lr 20.00 | ms/batch 168.69 | loss  5.35 | ppl   210.55\n",
      "INFO 2019-05-24 17:56:24,912: | epoch   1 | 13000/23759 batches | lr 20.00 | ms/batch 168.90 | loss  5.38 | ppl   216.74\n",
      "INFO 2019-05-24 17:56:58,692: | epoch   1 | 13200/23759 batches | lr 20.00 | ms/batch 168.90 | loss  5.19 | ppl   178.60\n",
      "INFO 2019-05-24 17:57:32,290: | epoch   1 | 13400/23759 batches | lr 20.00 | ms/batch 167.98 | loss  5.19 | ppl   178.87\n",
      "INFO 2019-05-24 17:58:05,985: | epoch   1 | 13600/23759 batches | lr 20.00 | ms/batch 168.48 | loss  5.29 | ppl   199.21\n",
      "INFO 2019-05-24 17:58:39,841: | epoch   1 | 13800/23759 batches | lr 20.00 | ms/batch 169.28 | loss  5.06 | ppl   157.11\n",
      "INFO 2019-05-24 17:59:13,543: | epoch   1 | 14000/23759 batches | lr 20.00 | ms/batch 168.51 | loss  5.17 | ppl   175.83\n",
      "INFO 2019-05-24 17:59:47,279: | epoch   1 | 14200/23759 batches | lr 20.00 | ms/batch 168.68 | loss  5.14 | ppl   171.14\n",
      "INFO 2019-05-24 18:00:21,068: | epoch   1 | 14400/23759 batches | lr 20.00 | ms/batch 168.94 | loss  5.24 | ppl   188.45\n",
      "INFO 2019-05-24 18:00:54,796: | epoch   1 | 14600/23759 batches | lr 20.00 | ms/batch 168.64 | loss  5.20 | ppl   180.89\n",
      "INFO 2019-05-24 18:01:28,561: | epoch   1 | 14800/23759 batches | lr 20.00 | ms/batch 168.82 | loss  5.29 | ppl   198.58\n",
      "INFO 2019-05-24 18:02:02,340: | epoch   1 | 15000/23759 batches | lr 20.00 | ms/batch 168.89 | loss  5.15 | ppl   172.33\n",
      "INFO 2019-05-24 18:02:36,144: | epoch   1 | 15200/23759 batches | lr 20.00 | ms/batch 169.02 | loss  5.28 | ppl   196.87\n",
      "INFO 2019-05-24 18:03:09,784: | epoch   1 | 15400/23759 batches | lr 20.00 | ms/batch 168.20 | loss  5.22 | ppl   184.47\n",
      "INFO 2019-05-24 18:03:43,453: | epoch   1 | 15600/23759 batches | lr 20.00 | ms/batch 168.34 | loss  5.16 | ppl   173.85\n",
      "INFO 2019-05-24 18:04:17,178: | epoch   1 | 15800/23759 batches | lr 20.00 | ms/batch 168.62 | loss  5.21 | ppl   182.36\n",
      "INFO 2019-05-24 18:04:50,927: | epoch   1 | 16000/23759 batches | lr 20.00 | ms/batch 168.74 | loss  5.00 | ppl   148.03\n",
      "INFO 2019-05-24 18:05:24,572: | epoch   1 | 16200/23759 batches | lr 20.00 | ms/batch 168.22 | loss  5.32 | ppl   204.00\n",
      "INFO 2019-05-24 18:05:58,245: | epoch   1 | 16400/23759 batches | lr 20.00 | ms/batch 168.36 | loss  5.03 | ppl   152.64\n",
      "INFO 2019-05-24 18:06:31,998: | epoch   1 | 16600/23759 batches | lr 20.00 | ms/batch 168.76 | loss  5.17 | ppl   176.78\n",
      "INFO 2019-05-24 18:07:05,756: | epoch   1 | 16800/23759 batches | lr 20.00 | ms/batch 168.79 | loss  5.20 | ppl   181.82\n",
      "INFO 2019-05-24 18:07:39,478: | epoch   1 | 17000/23759 batches | lr 20.00 | ms/batch 168.61 | loss  5.19 | ppl   179.35\n",
      "INFO 2019-05-24 18:08:13,199: | epoch   1 | 17200/23759 batches | lr 20.00 | ms/batch 168.60 | loss  5.16 | ppl   174.65\n",
      "INFO 2019-05-24 18:08:46,933: | epoch   1 | 17400/23759 batches | lr 20.00 | ms/batch 168.67 | loss  5.09 | ppl   162.00\n",
      "INFO 2019-05-24 18:09:20,635: | epoch   1 | 17600/23759 batches | lr 20.00 | ms/batch 168.51 | loss  5.08 | ppl   160.96\n",
      "INFO 2019-05-24 18:09:54,265: | epoch   1 | 17800/23759 batches | lr 20.00 | ms/batch 168.15 | loss  5.05 | ppl   156.32\n",
      "INFO 2019-05-24 18:10:28,000: | epoch   1 | 18000/23759 batches | lr 20.00 | ms/batch 168.67 | loss  5.16 | ppl   173.52\n",
      "INFO 2019-05-24 18:11:01,703: | epoch   1 | 18200/23759 batches | lr 20.00 | ms/batch 168.51 | loss  5.14 | ppl   171.25\n",
      "INFO 2019-05-24 18:11:35,278: | epoch   1 | 18400/23759 batches | lr 20.00 | ms/batch 167.87 | loss  5.27 | ppl   193.83\n",
      "INFO 2019-05-24 18:12:08,898: | epoch   1 | 18600/23759 batches | lr 20.00 | ms/batch 168.10 | loss  5.22 | ppl   185.29\n",
      "INFO 2019-05-24 18:12:42,600: | epoch   1 | 18800/23759 batches | lr 20.00 | ms/batch 168.51 | loss  5.02 | ppl   151.22\n",
      "INFO 2019-05-24 18:13:16,264: | epoch   1 | 19000/23759 batches | lr 20.00 | ms/batch 168.32 | loss  5.23 | ppl   187.61\n",
      "INFO 2019-05-24 18:13:49,965: | epoch   1 | 19200/23759 batches | lr 20.00 | ms/batch 168.50 | loss  5.07 | ppl   159.47\n",
      "INFO 2019-05-24 18:14:23,789: | epoch   1 | 19400/23759 batches | lr 20.00 | ms/batch 169.12 | loss  5.09 | ppl   162.15\n",
      "INFO 2019-05-24 18:14:57,654: | epoch   1 | 19600/23759 batches | lr 20.00 | ms/batch 169.32 | loss  4.96 | ppl   142.83\n",
      "INFO 2019-05-24 18:15:31,507: | epoch   1 | 19800/23759 batches | lr 20.00 | ms/batch 169.26 | loss  5.11 | ppl   165.27\n",
      "INFO 2019-05-24 18:16:05,262: | epoch   1 | 20000/23759 batches | lr 20.00 | ms/batch 168.77 | loss  5.18 | ppl   177.13\n",
      "INFO 2019-05-24 18:16:38,951: | epoch   1 | 20200/23759 batches | lr 20.00 | ms/batch 168.44 | loss  5.09 | ppl   162.49\n",
      "INFO 2019-05-24 18:17:12,735: | epoch   1 | 20400/23759 batches | lr 20.00 | ms/batch 168.92 | loss  5.05 | ppl   155.66\n",
      "INFO 2019-05-24 18:17:46,468: | epoch   1 | 20600/23759 batches | lr 20.00 | ms/batch 168.66 | loss  5.19 | ppl   178.81\n",
      "INFO 2019-05-24 18:18:20,073: | epoch   1 | 20800/23759 batches | lr 20.00 | ms/batch 168.02 | loss  5.04 | ppl   154.29\n",
      "INFO 2019-05-24 18:18:53,892: | epoch   1 | 21000/23759 batches | lr 20.00 | ms/batch 169.09 | loss  5.27 | ppl   195.35\n",
      "INFO 2019-05-24 18:19:27,643: | epoch   1 | 21200/23759 batches | lr 20.00 | ms/batch 168.75 | loss  5.16 | ppl   173.64\n",
      "INFO 2019-05-24 18:20:01,429: | epoch   1 | 21400/23759 batches | lr 20.00 | ms/batch 168.93 | loss  5.06 | ppl   157.24\n",
      "INFO 2019-05-24 18:20:35,133: | epoch   1 | 21600/23759 batches | lr 20.00 | ms/batch 168.52 | loss  5.12 | ppl   167.70\n",
      "INFO 2019-05-24 18:21:08,905: | epoch   1 | 21800/23759 batches | lr 20.00 | ms/batch 168.86 | loss  5.06 | ppl   158.04\n",
      "INFO 2019-05-24 18:21:42,652: | epoch   1 | 22000/23759 batches | lr 20.00 | ms/batch 168.73 | loss  5.02 | ppl   151.96\n",
      "INFO 2019-05-24 18:22:16,393: | epoch   1 | 22200/23759 batches | lr 20.00 | ms/batch 168.70 | loss  4.93 | ppl   138.83\n",
      "INFO 2019-05-24 18:22:50,066: | epoch   1 | 22400/23759 batches | lr 20.00 | ms/batch 168.36 | loss  4.97 | ppl   143.66\n",
      "INFO 2019-05-24 18:23:23,725: | epoch   1 | 22600/23759 batches | lr 20.00 | ms/batch 168.29 | loss  4.96 | ppl   142.92\n",
      "INFO 2019-05-24 18:23:57,306: | epoch   1 | 22800/23759 batches | lr 20.00 | ms/batch 167.90 | loss  5.12 | ppl   167.56\n",
      "INFO 2019-05-24 18:24:30,992: | epoch   1 | 23000/23759 batches | lr 20.00 | ms/batch 168.43 | loss  4.94 | ppl   139.74\n",
      "INFO 2019-05-24 18:25:04,698: | epoch   1 | 23200/23759 batches | lr 20.00 | ms/batch 168.53 | loss  4.98 | ppl   145.08\n",
      "INFO 2019-05-24 18:25:38,413: | epoch   1 | 23400/23759 batches | lr 20.00 | ms/batch 168.57 | loss  5.11 | ppl   165.47\n",
      "INFO 2019-05-24 18:26:12,081: | epoch   1 | 23600/23759 batches | lr 20.00 | ms/batch 168.34 | loss  5.06 | ppl   156.97\n",
      "INFO 2019-05-24 18:26:38,787: -----------------------------------------------------------------------------------------\n",
      "INFO 2019-05-24 18:26:38,788: Running eval\n",
      "INFO 2019-05-24 18:26:38,788: -----------------------------------------------------------------------------------------\n",
      "INFO 2019-05-24 18:26:44,233: |   200/33162 batches | loss 177.49\n",
      "INFO 2019-05-24 18:26:49,611: |   400/33162 batches | loss 359.28\n",
      "INFO 2019-05-24 18:26:55,016: |   600/33162 batches | loss 544.94\n",
      "INFO 2019-05-24 18:27:00,482: |   800/33162 batches | loss 723.97\n",
      "INFO 2019-05-24 18:27:05,932: |  1000/33162 batches | loss 907.55\n",
      "INFO 2019-05-24 18:27:11,370: |  1200/33162 batches | loss 1098.61\n",
      "INFO 2019-05-24 18:27:16,781: |  1400/33162 batches | loss 1284.48\n",
      "INFO 2019-05-24 18:27:22,200: |  1600/33162 batches | loss 1471.08\n",
      "INFO 2019-05-24 18:27:27,744: |  1800/33162 batches | loss 1662.04\n",
      "INFO 2019-05-24 18:27:33,171: |  2000/33162 batches | loss 1844.52\n",
      "INFO 2019-05-24 18:27:38,608: |  2200/33162 batches | loss 2026.43\n",
      "INFO 2019-05-24 18:27:44,042: |  2400/33162 batches | loss 2208.71\n",
      "INFO 2019-05-24 18:27:49,465: |  2600/33162 batches | loss 2395.35\n",
      "INFO 2019-05-24 18:27:54,886: |  2800/33162 batches | loss 2580.82\n",
      "INFO 2019-05-24 18:28:00,354: |  3000/33162 batches | loss 2762.34\n",
      "INFO 2019-05-24 18:28:05,794: |  3200/33162 batches | loss 2944.63\n",
      "INFO 2019-05-24 18:28:11,241: |  3400/33162 batches | loss 3133.87\n",
      "INFO 2019-05-24 18:28:16,695: |  3600/33162 batches | loss 3318.33\n",
      "INFO 2019-05-24 18:28:22,139: |  3800/33162 batches | loss 3494.73\n",
      "INFO 2019-05-24 18:28:27,575: |  4000/33162 batches | loss 3679.71\n",
      "INFO 2019-05-24 18:28:33,001: |  4200/33162 batches | loss 3867.66\n",
      "INFO 2019-05-24 18:28:38,457: |  4400/33162 batches | loss 4053.24\n",
      "INFO 2019-05-24 18:28:43,922: |  4600/33162 batches | loss 4240.14\n",
      "INFO 2019-05-24 18:28:49,371: |  4800/33162 batches | loss 4415.88\n",
      "INFO 2019-05-24 18:28:54,773: |  5000/33162 batches | loss 4595.30\n",
      "INFO 2019-05-24 18:29:00,233: |  5200/33162 batches | loss 4769.20\n",
      "INFO 2019-05-24 18:29:05,698: |  5400/33162 batches | loss 4948.02\n",
      "INFO 2019-05-24 18:29:11,109: |  5600/33162 batches | loss 5125.16\n",
      "INFO 2019-05-24 18:29:16,513: |  5800/33162 batches | loss 5291.49\n",
      "INFO 2019-05-24 18:29:22,008: |  6000/33162 batches | loss 5475.90\n",
      "INFO 2019-05-24 18:29:27,439: |  6200/33162 batches | loss 5660.43\n",
      "INFO 2019-05-24 18:29:32,882: |  6400/33162 batches | loss 5846.94\n",
      "INFO 2019-05-24 18:29:38,299: |  6600/33162 batches | loss 6025.46\n",
      "INFO 2019-05-24 18:29:43,741: |  6800/33162 batches | loss 6210.05\n",
      "INFO 2019-05-24 18:29:49,160: |  7000/33162 batches | loss 6397.42\n",
      "INFO 2019-05-24 18:29:54,549: |  7200/33162 batches | loss 6587.25\n",
      "INFO 2019-05-24 18:30:00,014: |  7400/33162 batches | loss 6772.81\n",
      "INFO 2019-05-24 18:30:05,406: |  7600/33162 batches | loss 6959.22\n",
      "INFO 2019-05-24 18:30:10,888: |  7800/33162 batches | loss 7143.63\n",
      "INFO 2019-05-24 18:30:16,367: |  8000/33162 batches | loss 7320.51\n",
      "INFO 2019-05-24 18:30:21,759: |  8200/33162 batches | loss 7496.56\n",
      "INFO 2019-05-24 18:30:27,216: |  8400/33162 batches | loss 7677.96\n",
      "INFO 2019-05-24 18:30:32,659: |  8600/33162 batches | loss 7862.13\n",
      "INFO 2019-05-24 18:30:38,087: |  8800/33162 batches | loss 8052.01\n",
      "INFO 2019-05-24 18:30:43,508: |  9000/33162 batches | loss 8232.60\n",
      "INFO 2019-05-24 18:30:48,951: |  9200/33162 batches | loss 8409.63\n",
      "INFO 2019-05-24 18:30:54,403: |  9400/33162 batches | loss 8595.88\n",
      "INFO 2019-05-24 18:30:59,790: |  9600/33162 batches | loss 8776.98\n",
      "INFO 2019-05-24 18:31:05,278: |  9800/33162 batches | loss 8956.72\n",
      "INFO 2019-05-24 18:31:10,683: | 10000/33162 batches | loss 9140.14\n",
      "INFO 2019-05-24 18:31:16,203: | 10200/33162 batches | loss 9322.94\n",
      "INFO 2019-05-24 18:31:21,600: | 10400/33162 batches | loss 9506.68\n",
      "INFO 2019-05-24 18:31:27,010: | 10600/33162 batches | loss 9691.13\n",
      "INFO 2019-05-24 18:31:32,434: | 10800/33162 batches | loss 9868.81\n",
      "INFO 2019-05-24 18:31:37,868: | 11000/33162 batches | loss 10045.15\n",
      "INFO 2019-05-24 18:31:43,345: | 11200/33162 batches | loss 10235.67\n",
      "INFO 2019-05-24 18:31:48,760: | 11400/33162 batches | loss 10421.78\n",
      "INFO 2019-05-24 18:31:54,206: | 11600/33162 batches | loss 10601.35\n",
      "INFO 2019-05-24 18:31:59,644: | 11800/33162 batches | loss 10786.92\n",
      "INFO 2019-05-24 18:32:05,069: | 12000/33162 batches | loss 10967.48\n",
      "INFO 2019-05-24 18:32:10,500: | 12200/33162 batches | loss 11155.80\n",
      "INFO 2019-05-24 18:32:15,938: | 12400/33162 batches | loss 11339.44\n",
      "INFO 2019-05-24 18:32:21,337: | 12600/33162 batches | loss 11520.15\n",
      "INFO 2019-05-24 18:32:26,787: | 12800/33162 batches | loss 11703.93\n",
      "INFO 2019-05-24 18:32:32,237: | 13000/33162 batches | loss 11882.26\n",
      "INFO 2019-05-24 18:32:37,640: | 13200/33162 batches | loss 12059.49\n",
      "INFO 2019-05-24 18:32:43,092: | 13400/33162 batches | loss 12240.69\n",
      "INFO 2019-05-24 18:32:48,508: | 13600/33162 batches | loss 12421.51\n",
      "INFO 2019-05-24 18:32:53,932: | 13800/33162 batches | loss 12598.35\n",
      "INFO 2019-05-24 18:32:59,361: | 14000/33162 batches | loss 12779.78\n",
      "INFO 2019-05-24 18:33:04,796: | 14200/33162 batches | loss 12964.17\n",
      "INFO 2019-05-24 18:33:10,226: | 14400/33162 batches | loss 13152.67\n",
      "INFO 2019-05-24 18:33:15,672: | 14600/33162 batches | loss 13345.18\n",
      "INFO 2019-05-24 18:33:21,098: | 14800/33162 batches | loss 13530.83\n",
      "INFO 2019-05-24 18:33:26,503: | 15000/33162 batches | loss 13709.86\n",
      "INFO 2019-05-24 18:33:31,958: | 15200/33162 batches | loss 13889.48\n",
      "INFO 2019-05-24 18:33:37,379: | 15400/33162 batches | loss 14074.73\n",
      "INFO 2019-05-24 18:33:42,794: | 15600/33162 batches | loss 14260.56\n",
      "INFO 2019-05-24 18:33:48,276: | 15800/33162 batches | loss 14443.94\n",
      "INFO 2019-05-24 18:33:53,680: | 16000/33162 batches | loss 14629.17\n",
      "INFO 2019-05-24 18:33:59,104: | 16200/33162 batches | loss 14808.21\n",
      "INFO 2019-05-24 18:34:04,535: | 16400/33162 batches | loss 14987.81\n",
      "INFO 2019-05-24 18:34:09,957: | 16600/33162 batches | loss 15168.58\n",
      "INFO 2019-05-24 18:34:15,392: | 16800/33162 batches | loss 15348.96\n",
      "INFO 2019-05-24 18:34:20,821: | 17000/33162 batches | loss 15531.21\n",
      "INFO 2019-05-24 18:34:26,262: | 17200/33162 batches | loss 15707.69\n",
      "INFO 2019-05-24 18:34:31,719: | 17400/33162 batches | loss 15885.81\n",
      "INFO 2019-05-24 18:34:37,137: | 17600/33162 batches | loss 16069.96\n",
      "INFO 2019-05-24 18:34:42,538: | 17800/33162 batches | loss 16248.74\n",
      "INFO 2019-05-24 18:34:48,132: | 18000/33162 batches | loss 16433.19\n",
      "INFO 2019-05-24 18:34:53,524: | 18200/33162 batches | loss 16611.22\n",
      "INFO 2019-05-24 18:34:58,931: | 18400/33162 batches | loss 16795.86\n",
      "INFO 2019-05-24 18:35:04,344: | 18600/33162 batches | loss 16984.32\n",
      "INFO 2019-05-24 18:35:09,757: | 18800/33162 batches | loss 17163.93\n",
      "INFO 2019-05-24 18:35:15,166: | 19000/33162 batches | loss 17346.51\n",
      "INFO 2019-05-24 18:35:20,564: | 19200/33162 batches | loss 17525.00\n",
      "INFO 2019-05-24 18:35:26,018: | 19400/33162 batches | loss 17702.11\n",
      "INFO 2019-05-24 18:35:31,484: | 19600/33162 batches | loss 17886.70\n",
      "INFO 2019-05-24 18:35:36,912: | 19800/33162 batches | loss 18063.54\n",
      "INFO 2019-05-24 18:35:42,337: | 20000/33162 batches | loss 18241.04\n",
      "INFO 2019-05-24 18:35:47,752: | 20200/33162 batches | loss 18412.80\n",
      "INFO 2019-05-24 18:35:53,161: | 20400/33162 batches | loss 18590.25\n",
      "INFO 2019-05-24 18:35:58,600: | 20600/33162 batches | loss 18774.54\n",
      "INFO 2019-05-24 18:36:04,027: | 20800/33162 batches | loss 18953.22\n",
      "INFO 2019-05-24 18:36:09,466: | 21000/33162 batches | loss 19133.34\n",
      "INFO 2019-05-24 18:36:14,871: | 21200/33162 batches | loss 19318.07\n",
      "INFO 2019-05-24 18:36:20,294: | 21400/33162 batches | loss 19498.79\n",
      "INFO 2019-05-24 18:36:25,723: | 21600/33162 batches | loss 19674.61\n",
      "INFO 2019-05-24 18:36:31,147: | 21800/33162 batches | loss 19861.93\n",
      "INFO 2019-05-24 18:36:36,635: | 22000/33162 batches | loss 20040.72\n",
      "INFO 2019-05-24 18:36:42,063: | 22200/33162 batches | loss 20218.56\n",
      "INFO 2019-05-24 18:36:47,465: | 22400/33162 batches | loss 20399.72\n",
      "INFO 2019-05-24 18:36:52,879: | 22600/33162 batches | loss 20581.10\n",
      "INFO 2019-05-24 18:36:58,298: | 22800/33162 batches | loss 20763.52\n",
      "INFO 2019-05-24 18:37:03,758: | 23000/33162 batches | loss 20944.11\n",
      "INFO 2019-05-24 18:37:09,173: | 23200/33162 batches | loss 21126.13\n",
      "INFO 2019-05-24 18:37:14,617: | 23400/33162 batches | loss 21309.99\n",
      "INFO 2019-05-24 18:37:20,054: | 23600/33162 batches | loss 21496.36\n",
      "INFO 2019-05-24 18:37:25,503: | 23800/33162 batches | loss 21678.88\n",
      "INFO 2019-05-24 18:37:30,904: | 24000/33162 batches | loss 21863.15\n",
      "INFO 2019-05-24 18:37:36,357: | 24200/33162 batches | loss 22042.29\n",
      "INFO 2019-05-24 18:37:41,787: | 24400/33162 batches | loss 22226.20\n",
      "INFO 2019-05-24 18:37:47,174: | 24600/33162 batches | loss 22396.57\n",
      "INFO 2019-05-24 18:37:52,655: | 24800/33162 batches | loss 22574.35\n",
      "INFO 2019-05-24 18:37:58,053: | 25000/33162 batches | loss 22755.21\n",
      "INFO 2019-05-24 18:38:03,484: | 25200/33162 batches | loss 22930.81\n",
      "INFO 2019-05-24 18:38:08,892: | 25400/33162 batches | loss 23103.85\n",
      "INFO 2019-05-24 18:38:14,331: | 25600/33162 batches | loss 23289.76\n",
      "INFO 2019-05-24 18:38:19,821: | 25800/33162 batches | loss 23475.19\n",
      "INFO 2019-05-24 18:38:25,218: | 26000/33162 batches | loss 23655.72\n",
      "INFO 2019-05-24 18:38:30,709: | 26200/33162 batches | loss 23842.84\n",
      "INFO 2019-05-24 18:38:36,099: | 26400/33162 batches | loss 24030.92\n",
      "INFO 2019-05-24 18:38:41,540: | 26600/33162 batches | loss 24215.63\n",
      "INFO 2019-05-24 18:38:46,960: | 26800/33162 batches | loss 24399.92\n",
      "INFO 2019-05-24 18:38:52,374: | 27000/33162 batches | loss 24585.59\n",
      "INFO 2019-05-24 18:38:57,798: | 27200/33162 batches | loss 24769.01\n",
      "INFO 2019-05-24 18:39:03,219: | 27400/33162 batches | loss 24955.37\n",
      "INFO 2019-05-24 18:39:08,673: | 27600/33162 batches | loss 25140.48\n",
      "INFO 2019-05-24 18:39:14,100: | 27800/33162 batches | loss 25322.20\n",
      "INFO 2019-05-24 18:39:19,600: | 28000/33162 batches | loss 25509.34\n",
      "INFO 2019-05-24 18:39:25,008: | 28200/33162 batches | loss 25697.39\n",
      "INFO 2019-05-24 18:39:30,423: | 28400/33162 batches | loss 25884.37\n",
      "INFO 2019-05-24 18:39:35,852: | 28600/33162 batches | loss 26068.95\n",
      "INFO 2019-05-24 18:39:41,289: | 28800/33162 batches | loss 26252.30\n",
      "INFO 2019-05-24 18:39:46,832: | 29000/33162 batches | loss 26432.81\n",
      "INFO 2019-05-24 18:39:52,208: | 29200/33162 batches | loss 26609.68\n",
      "INFO 2019-05-24 18:39:57,633: | 29400/33162 batches | loss 26790.94\n",
      "INFO 2019-05-24 18:40:03,047: | 29600/33162 batches | loss 26973.57\n",
      "INFO 2019-05-24 18:40:08,438: | 29800/33162 batches | loss 27157.75\n",
      "INFO 2019-05-24 18:40:13,886: | 30000/33162 batches | loss 27342.07\n",
      "INFO 2019-05-24 18:40:19,337: | 30200/33162 batches | loss 27526.27\n",
      "INFO 2019-05-24 18:40:24,798: | 30400/33162 batches | loss 27708.79\n",
      "INFO 2019-05-24 18:40:30,198: | 30600/33162 batches | loss 27895.70\n",
      "INFO 2019-05-24 18:40:35,752: | 30800/33162 batches | loss 28079.26\n",
      "INFO 2019-05-24 18:40:41,150: | 31000/33162 batches | loss 28265.14\n",
      "INFO 2019-05-24 18:40:46,562: | 31200/33162 batches | loss 28447.47\n",
      "INFO 2019-05-24 18:40:51,988: | 31400/33162 batches | loss 28637.49\n",
      "INFO 2019-05-24 18:40:57,384: | 31600/33162 batches | loss 28820.42\n",
      "INFO 2019-05-24 18:41:02,904: | 31800/33162 batches | loss 29008.23\n",
      "INFO 2019-05-24 18:41:08,307: | 32000/33162 batches | loss 29188.89\n",
      "INFO 2019-05-24 18:41:13,731: | 32200/33162 batches | loss 29374.78\n",
      "INFO 2019-05-24 18:41:19,177: | 32400/33162 batches | loss 29551.00\n",
      "INFO 2019-05-24 18:41:24,566: | 32600/33162 batches | loss 29736.24\n",
      "INFO 2019-05-24 18:41:29,973: | 32800/33162 batches | loss 29915.92\n",
      "INFO 2019-05-24 18:41:35,454: | 33000/33162 batches | loss 30096.56\n",
      "INFO 2019-05-24 18:41:39,815: -----------------------------------------------------------------------------------------\n",
      "INFO 2019-05-24 18:41:39,816: | end of epoch   1 | time: 4912.84s | valid loss  5.21 | valid ppl   183.22\n",
      "INFO 2019-05-24 18:41:39,816: -----------------------------------------------------------------------------------------\n",
      "INFO 2019-05-24 18:42:15,821: | epoch   2 |   200/23759 batches | lr 20.00 | ms/batch 170.14 | loss  5.11 | ppl   165.73\n",
      "INFO 2019-05-24 18:42:49,438: | epoch   2 |   400/23759 batches | lr 20.00 | ms/batch 168.08 | loss  5.29 | ppl   197.87\n",
      "INFO 2019-05-24 18:43:23,122: | epoch   2 |   600/23759 batches | lr 20.00 | ms/batch 168.41 | loss  5.11 | ppl   165.04\n",
      "INFO 2019-05-24 18:43:56,759: | epoch   2 |   800/23759 batches | lr 20.00 | ms/batch 168.18 | loss  5.05 | ppl   156.00\n",
      "INFO 2019-05-24 18:44:30,432: | epoch   2 |  1000/23759 batches | lr 20.00 | ms/batch 168.36 | loss  5.09 | ppl   161.84\n",
      "INFO 2019-05-24 18:45:04,076: | epoch   2 |  1200/23759 batches | lr 20.00 | ms/batch 168.22 | loss  5.00 | ppl   147.69\n",
      "INFO 2019-05-24 18:45:37,755: | epoch   2 |  1400/23759 batches | lr 20.00 | ms/batch 168.39 | loss  5.06 | ppl   157.06\n",
      "INFO 2019-05-24 18:46:11,439: | epoch   2 |  1600/23759 batches | lr 20.00 | ms/batch 168.42 | loss  5.05 | ppl   155.95\n",
      "INFO 2019-05-24 18:46:44,991: | epoch   2 |  1800/23759 batches | lr 20.00 | ms/batch 167.75 | loss  4.99 | ppl   147.56\n",
      "INFO 2019-05-24 18:47:18,757: | epoch   2 |  2000/23759 batches | lr 20.00 | ms/batch 168.83 | loss  4.80 | ppl   121.06\n",
      "INFO 2019-05-24 18:47:52,502: | epoch   2 |  2200/23759 batches | lr 20.00 | ms/batch 168.72 | loss  4.98 | ppl   146.16\n",
      "INFO 2019-05-24 18:48:26,241: | epoch   2 |  2400/23759 batches | lr 20.00 | ms/batch 168.69 | loss  4.84 | ppl   126.63\n",
      "INFO 2019-05-24 18:49:00,036: | epoch   2 |  2600/23759 batches | lr 20.00 | ms/batch 168.97 | loss  5.11 | ppl   165.29\n",
      "INFO 2019-05-24 18:49:33,750: | epoch   2 |  2800/23759 batches | lr 20.00 | ms/batch 168.57 | loss  5.20 | ppl   181.45\n",
      "INFO 2019-05-24 18:50:07,389: | epoch   2 |  3000/23759 batches | lr 20.00 | ms/batch 168.19 | loss  5.18 | ppl   177.79\n",
      "INFO 2019-05-24 18:50:41,283: | epoch   2 |  3200/23759 batches | lr 20.00 | ms/batch 169.47 | loss  4.99 | ppl   147.63\n",
      "INFO 2019-05-24 18:51:14,967: | epoch   2 |  3400/23759 batches | lr 20.00 | ms/batch 168.42 | loss  5.04 | ppl   154.08\n",
      "INFO 2019-05-24 18:51:48,612: | epoch   2 |  3600/23759 batches | lr 20.00 | ms/batch 168.22 | loss  5.27 | ppl   194.10\n",
      "INFO 2019-05-24 18:52:22,372: | epoch   2 |  3800/23759 batches | lr 20.00 | ms/batch 168.80 | loss  5.13 | ppl   169.86\n",
      "INFO 2019-05-24 18:52:56,103: | epoch   2 |  4000/23759 batches | lr 20.00 | ms/batch 168.66 | loss  5.21 | ppl   183.66\n",
      "INFO 2019-05-24 18:53:29,805: | epoch   2 |  4200/23759 batches | lr 20.00 | ms/batch 168.51 | loss  4.96 | ppl   142.56\n",
      "INFO 2019-05-24 18:54:03,497: | epoch   2 |  4400/23759 batches | lr 20.00 | ms/batch 168.45 | loss  5.21 | ppl   183.01\n",
      "INFO 2019-05-24 18:54:37,231: | epoch   2 |  4600/23759 batches | lr 20.00 | ms/batch 168.66 | loss  5.23 | ppl   187.20\n",
      "INFO 2019-05-24 18:55:11,021: | epoch   2 |  4800/23759 batches | lr 20.00 | ms/batch 168.95 | loss  5.06 | ppl   158.01\n",
      "INFO 2019-05-24 18:55:44,791: | epoch   2 |  5000/23759 batches | lr 20.00 | ms/batch 168.85 | loss  4.99 | ppl   147.09\n",
      "INFO 2019-05-24 18:56:18,624: | epoch   2 |  5200/23759 batches | lr 20.00 | ms/batch 169.16 | loss  5.04 | ppl   154.40\n",
      "INFO 2019-05-24 18:56:52,305: | epoch   2 |  5400/23759 batches | lr 20.00 | ms/batch 168.40 | loss  4.96 | ppl   142.34\n",
      "INFO 2019-05-24 18:57:26,129: | epoch   2 |  5600/23759 batches | lr 20.00 | ms/batch 169.12 | loss  5.11 | ppl   166.08\n",
      "INFO 2019-05-24 18:57:59,895: | epoch   2 |  5800/23759 batches | lr 20.00 | ms/batch 168.83 | loss  4.98 | ppl   144.90\n",
      "INFO 2019-05-24 18:58:33,591: | epoch   2 |  6000/23759 batches | lr 20.00 | ms/batch 168.48 | loss  5.07 | ppl   159.88\n",
      "INFO 2019-05-24 18:59:07,276: | epoch   2 |  6200/23759 batches | lr 20.00 | ms/batch 168.42 | loss  5.15 | ppl   172.64\n",
      "INFO 2019-05-24 18:59:41,027: | epoch   2 |  6400/23759 batches | lr 20.00 | ms/batch 168.75 | loss  4.98 | ppl   145.66\n",
      "INFO 2019-05-24 19:00:14,708: | epoch   2 |  6600/23759 batches | lr 20.00 | ms/batch 168.40 | loss  5.07 | ppl   159.63\n",
      "INFO 2019-05-24 19:00:48,497: | epoch   2 |  6800/23759 batches | lr 20.00 | ms/batch 168.94 | loss  5.04 | ppl   154.61\n",
      "INFO 2019-05-24 19:01:22,264: | epoch   2 |  7000/23759 batches | lr 20.00 | ms/batch 168.84 | loss  4.92 | ppl   136.99\n",
      "INFO 2019-05-24 19:01:55,823: | epoch   2 |  7200/23759 batches | lr 20.00 | ms/batch 167.79 | loss  4.83 | ppl   125.06\n",
      "INFO 2019-05-24 19:02:29,458: | epoch   2 |  7400/23759 batches | lr 20.00 | ms/batch 168.17 | loss  4.73 | ppl   113.42\n",
      "INFO 2019-05-24 19:03:03,220: | epoch   2 |  7600/23759 batches | lr 20.00 | ms/batch 168.81 | loss  4.91 | ppl   135.68\n",
      "INFO 2019-05-24 19:03:36,963: | epoch   2 |  7800/23759 batches | lr 20.00 | ms/batch 168.71 | loss  4.90 | ppl   134.86\n",
      "INFO 2019-05-24 19:04:10,691: | epoch   2 |  8000/23759 batches | lr 20.00 | ms/batch 168.64 | loss  4.96 | ppl   142.31\n",
      "INFO 2019-05-24 19:04:44,504: | epoch   2 |  8200/23759 batches | lr 20.00 | ms/batch 169.06 | loss  5.00 | ppl   147.96\n",
      "INFO 2019-05-24 19:05:18,222: | epoch   2 |  8400/23759 batches | lr 20.00 | ms/batch 168.59 | loss  5.05 | ppl   156.01\n",
      "INFO 2019-05-24 19:05:51,974: | epoch   2 |  8600/23759 batches | lr 20.00 | ms/batch 168.75 | loss  4.96 | ppl   142.10\n",
      "INFO 2019-05-24 19:06:25,680: | epoch   2 |  8800/23759 batches | lr 20.00 | ms/batch 168.53 | loss  4.90 | ppl   134.74\n",
      "INFO 2019-05-24 19:06:59,434: | epoch   2 |  9000/23759 batches | lr 20.00 | ms/batch 168.76 | loss  5.09 | ppl   161.84\n",
      "INFO 2019-05-24 19:07:33,038: | epoch   2 |  9200/23759 batches | lr 20.00 | ms/batch 168.02 | loss  5.10 | ppl   164.74\n",
      "INFO 2019-05-24 19:08:06,723: | epoch   2 |  9400/23759 batches | lr 20.00 | ms/batch 168.42 | loss  5.16 | ppl   173.79\n",
      "INFO 2019-05-24 19:08:40,339: | epoch   2 |  9600/23759 batches | lr 20.00 | ms/batch 168.07 | loss  5.10 | ppl   164.30\n",
      "INFO 2019-05-24 19:09:14,121: | epoch   2 |  9800/23759 batches | lr 20.00 | ms/batch 168.91 | loss  4.97 | ppl   143.51\n",
      "INFO 2019-05-24 19:09:47,741: | epoch   2 | 10000/23759 batches | lr 20.00 | ms/batch 168.10 | loss  4.92 | ppl   136.37\n",
      "INFO 2019-05-24 19:10:21,484: | epoch   2 | 10200/23759 batches | lr 20.00 | ms/batch 168.71 | loss  4.93 | ppl   138.74\n",
      "INFO 2019-05-24 19:10:55,166: | epoch   2 | 10400/23759 batches | lr 20.00 | ms/batch 168.41 | loss  4.84 | ppl   126.00\n",
      "INFO 2019-05-24 19:11:28,785: | epoch   2 | 10600/23759 batches | lr 20.00 | ms/batch 168.09 | loss  5.08 | ppl   160.26\n"
     ]
    }
   ],
   "source": [
    "train(model, corpus, criterion, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# timestamp = datetime.datetime.now()\n",
    "# with open(MODEL_FILE_NAME.format(timestamp), 'wb') as f:\n",
    "#     torch.save(model, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(MODEL_FILE_NAME.format(timestamp), 'rb') as f:\n",
    "with open('models/trained_models/model-2019-05-24 17:19:46.971655.pt', 'rb') as f:\n",
    "    model = torch.load(f)\n",
    "    # after load the rnn params are not a continuous chunk of memory\n",
    "    # this makes them a continuous chunk, and will speed up forward pass\n",
    "    model.rnn.flatten_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO 2019-05-27 10:57:05,109: -----------------------------------------------------------------------------------------\n",
      "INFO 2019-05-27 10:57:05,110: Running eval\n",
      "INFO 2019-05-27 10:57:05,110: -----------------------------------------------------------------------------------------\n",
      "INFO 2019-05-27 10:57:31,470: |  1000/42211 batches | loss 175.47\n",
      "INFO 2019-05-27 10:57:57,898: |  2000/42211 batches | loss 175.93\n",
      "INFO 2019-05-27 10:58:24,412: |  3000/42211 batches | loss 176.24\n",
      "INFO 2019-05-27 10:58:50,994: |  4000/42211 batches | loss 176.12\n",
      "INFO 2019-05-27 10:59:17,711: |  5000/42211 batches | loss 175.86\n",
      "INFO 2019-05-27 10:59:44,515: |  6000/42211 batches | loss 175.90\n",
      "INFO 2019-05-27 11:00:11,298: |  7000/42211 batches | loss 175.92\n",
      "INFO 2019-05-27 11:00:38,091: |  8000/42211 batches | loss 176.16\n",
      "INFO 2019-05-27 11:01:04,898: |  9000/42211 batches | loss 176.03\n",
      "INFO 2019-05-27 11:01:31,771: | 10000/42211 batches | loss 176.04\n",
      "INFO 2019-05-27 11:01:58,692: | 11000/42211 batches | loss 175.98\n",
      "INFO 2019-05-27 11:02:25,636: | 12000/42211 batches | loss 175.79\n",
      "INFO 2019-05-27 11:02:52,621: | 13000/42211 batches | loss 176.28\n",
      "INFO 2019-05-27 11:03:19,625: | 14000/42211 batches | loss 176.09\n",
      "INFO 2019-05-27 11:03:46,666: | 15000/42211 batches | loss 175.91\n",
      "INFO 2019-05-27 11:06:28,953: | 21000/42211 batches | loss 175.49\n",
      "INFO 2019-05-27 11:06:56,057: | 22000/42211 batches | loss 175.48\n",
      "INFO 2019-05-27 11:07:23,091: | 23000/42211 batches | loss 175.46\n",
      "INFO 2019-05-27 11:07:50,256: | 24000/42211 batches | loss 175.49\n",
      "INFO 2019-05-27 11:08:17,323: | 25000/42211 batches | loss 175.52\n",
      "INFO 2019-05-27 11:08:44,392: | 26000/42211 batches | loss 175.58\n",
      "INFO 2019-05-27 11:09:11,445: | 27000/42211 batches | loss 175.67\n",
      "INFO 2019-05-27 11:09:38,418: | 28000/42211 batches | loss 175.73\n",
      "INFO 2019-05-27 11:10:05,249: | 29000/42211 batches | loss 175.78\n",
      "INFO 2019-05-27 11:10:32,054: | 30000/42211 batches | loss 175.86\n",
      "INFO 2019-05-27 11:10:58,873: | 31000/42211 batches | loss 175.93\n",
      "INFO 2019-05-27 11:11:25,678: | 32000/42211 batches | loss 175.88\n",
      "INFO 2019-05-27 11:11:52,473: | 33000/42211 batches | loss 175.90\n",
      "INFO 2019-05-27 11:12:19,316: | 34000/42211 batches | loss 175.94\n",
      "INFO 2019-05-27 11:12:46,221: | 35000/42211 batches | loss 176.05\n",
      "INFO 2019-05-27 11:13:13,208: | 36000/42211 batches | loss 176.09\n",
      "INFO 2019-05-27 11:13:40,229: | 37000/42211 batches | loss 176.02\n",
      "INFO 2019-05-27 11:14:07,277: | 38000/42211 batches | loss 176.02\n",
      "INFO 2019-05-27 11:14:34,259: | 39000/42211 batches | loss 176.14\n",
      "INFO 2019-05-27 11:15:01,315: | 40000/42211 batches | loss 176.25\n",
      "INFO 2019-05-27 11:15:28,366: | 41000/42211 batches | loss 176.22\n",
      "INFO 2019-05-27 11:15:55,734: | 42000/42211 batches | loss 176.29\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "5.038112595037704"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(model, corpus, criterion, device, use_test_data=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test perplexity:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "154.1787425140638"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "print('Test perplexity:')\n",
    "math.exp(5.038112595037704)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gabrielamelo/anaconda3/envs/wsc_port/lib/python3.6/site-packages/torch/serialization.py:435: SourceChangeWarning: source code of class 'src.model.RNNModel' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n"
     ]
    }
   ],
   "source": [
    "model_file_name = get_latest_model_file()\n",
    "with open(model_file_name, 'rb') as f:\n",
    "    model = torch.load(f)\n",
    "    model.rnn.flatten_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO 2019-06-17 14:23:18,863: -----------------------------------------------------------------------------------------\n",
      "INFO 2019-06-17 14:23:18,864: Running eval\n",
      "INFO 2019-06-17 14:23:18,864: -----------------------------------------------------------------------------------------\n",
      "33163it [15:50, 34.89it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4.516977660576491"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(model, corpus, criterion, device, use_test_data=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation perplexity:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "91.55845864543299"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "print('Validation perplexity:')\n",
    "math.exp(4.516977660576491)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO 2019-06-17 14:48:39,366: -----------------------------------------------------------------------------------------\n",
      "INFO 2019-06-17 14:48:39,366: Running eval\n",
      "INFO 2019-06-17 14:48:39,367: -----------------------------------------------------------------------------------------\n",
      "23760it [21:39, 18.28it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3.921935869550003"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(model, corpus, criterion, device, use_train_data=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training perplexity:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "50.498107965513185"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "print('Training perplexity:')\n",
    "math.exp(3.921935869550003)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wsc_port",
   "language": "python",
   "name": "wsc_port"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
