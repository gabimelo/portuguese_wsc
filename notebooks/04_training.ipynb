{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('..')\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "import torch.nn as nn\n",
    "\n",
    "from src.consts import *\n",
    "from src.main import main, setup_torch, get_corpus\n",
    "from src.model import RNNModel\n",
    "from src.training import train, evaluate\n",
    "\n",
    "from notebooks.utils import summary, check_cuda_mem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_data_paralellization = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO 2019-05-22 18:21:03,146: | epoch   1 |   200/23759 batches | lr 20.00 | ms/batch 168.00 | loss  9.71 | ppl 16456.22\n",
      "INFO 2019-05-22 18:21:36,727: | epoch   1 |   400/23759 batches | lr 20.00 | ms/batch 167.90 | loss  8.26 | ppl  3855.86\n",
      "INFO 2019-05-22 18:22:10,481: | epoch   1 |   600/23759 batches | lr 20.00 | ms/batch 168.77 | loss  7.49 | ppl  1790.88\n",
      "INFO 2019-05-22 18:22:44,297: | epoch   1 |   800/23759 batches | lr 20.00 | ms/batch 169.08 | loss  7.17 | ppl  1305.10\n",
      "INFO 2019-05-22 18:23:18,109: | epoch   1 |  1000/23759 batches | lr 20.00 | ms/batch 169.06 | loss  6.97 | ppl  1060.82\n",
      "INFO 2019-05-22 18:23:51,967: | epoch   1 |  1200/23759 batches | lr 20.00 | ms/batch 169.28 | loss  6.73 | ppl   837.63\n",
      "INFO 2019-05-22 18:24:21,027: -----------------------------------------------------------------------------------------\n",
      "INFO 2019-05-22 18:24:21,028: Exiting from training early\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'models/trained_models/model-2019-05-22 18:20:29.546748.pt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-a9d3f82e209e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mcriterion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCrossEntropyLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorpus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/media/gabrielamelo/Novo volume/Projects/portuguese_wsc/src/training.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, corpus, criterion, device)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0mtest_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatchify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEVAL_BATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m     \u001b[0mget_training_results\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorpus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimestamp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/gabrielamelo/Novo volume/Projects/portuguese_wsc/src/training.py\u001b[0m in \u001b[0;36mget_training_results\u001b[0;34m(model, corpus, criterion, device, timestamp)\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_training_results\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorpus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimestamp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m     \u001b[0;31m# Load the best saved model.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMODEL_FILE_NAME\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimestamp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[0;31m# after load the rnn params are not a continuous chunk of memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'models/trained_models/model-2019-05-22 18:20:29.546748.pt'"
     ]
    }
   ],
   "source": [
    "setup_torch()\n",
    "device = torch.device(\"cuda\" if USE_CUDA else \"cpu\")\n",
    "corpus = get_corpus()\n",
    "\n",
    "# TODO remove these two lines\n",
    "assert len(corpus.dictionary) == 602755\n",
    "assert corpus.valid.size()[0] == 11606861\n",
    "\n",
    "ntokens = len(corpus.dictionary)\n",
    "model = RNNModel(MODEL_TYPE, ntokens, EMBEDDINGS_SIZE, HIDDEN_UNIT_COUNT, LAYER_COUNT, DROPOUT_PROB,\n",
    "                 TIED)\n",
    "if use_data_paralellization or USE_DATA_PARALLELIZATION:\n",
    "    model = CustomDataParallel(model)\n",
    "else:\n",
    "    model.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "train(model, corpus, criterion, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO 2019-05-21 19:16:03,766: | epoch   1 |   200/23759 batches | lr 20.00 | ms/batch 174.28 | loss  9.67 | ppl 15815.59\n",
      "INFO 2019-05-21 19:16:38,230: | epoch   1 |   400/23759 batches | lr 20.00 | ms/batch 172.31 | loss  8.26 | ppl  3872.08\n",
      "INFO 2019-05-21 19:17:12,807: | epoch   1 |   600/23759 batches | lr 20.00 | ms/batch 172.88 | loss  7.49 | ppl  1783.08\n",
      "INFO 2019-05-21 19:17:47,428: | epoch   1 |   800/23759 batches | lr 20.00 | ms/batch 173.11 | loss  7.18 | ppl  1316.14\n",
      "INFO 2019-05-21 19:18:22,444: | epoch   1 |  1000/23759 batches | lr 20.00 | ms/batch 175.07 | loss  6.97 | ppl  1066.55\n",
      "INFO 2019-05-21 19:18:57,633: | epoch   1 |  1200/23759 batches | lr 20.00 | ms/batch 175.94 | loss  6.75 | ppl   851.74\n",
      "INFO 2019-05-21 19:19:32,555: | epoch   1 |  1400/23759 batches | lr 20.00 | ms/batch 174.61 | loss  6.61 | ppl   745.03\n",
      "INFO 2019-05-21 19:20:07,969: | epoch   1 |  1600/23759 batches | lr 20.00 | ms/batch 177.07 | loss  6.50 | ppl   664.76\n",
      "INFO 2019-05-21 19:20:43,205: | epoch   1 |  1800/23759 batches | lr 20.00 | ms/batch 176.18 | loss  6.32 | ppl   556.70\n",
      "INFO 2019-05-21 19:21:18,328: | epoch   1 |  2000/23759 batches | lr 20.00 | ms/batch 175.61 | loss  6.10 | ppl   448.02\n",
      "INFO 2019-05-21 19:21:53,303: | epoch   1 |  2200/23759 batches | lr 20.00 | ms/batch 174.88 | loss  6.20 | ppl   491.06\n",
      "INFO 2019-05-21 19:22:28,246: | epoch   1 |  2400/23759 batches | lr 20.00 | ms/batch 174.71 | loss  5.99 | ppl   398.85\n",
      "INFO 2019-05-21 19:23:03,080: | epoch   1 |  2600/23759 batches | lr 20.00 | ms/batch 174.17 | loss  6.16 | ppl   475.62\n",
      "INFO 2019-05-21 19:23:37,984: | epoch   1 |  2800/23759 batches | lr 20.00 | ms/batch 174.52 | loss  6.21 | ppl   498.85\n",
      "INFO 2019-05-21 19:24:12,950: | epoch   1 |  3000/23759 batches | lr 20.00 | ms/batch 174.82 | loss  6.17 | ppl   475.85\n",
      "INFO 2019-05-21 19:24:47,942: | epoch   1 |  3200/23759 batches | lr 20.00 | ms/batch 174.96 | loss  5.95 | ppl   383.25\n",
      "INFO 2019-05-21 19:25:22,905: | epoch   1 |  3400/23759 batches | lr 20.00 | ms/batch 174.81 | loss  5.92 | ppl   371.40\n",
      "INFO 2019-05-21 19:25:57,841: | epoch   1 |  3600/23759 batches | lr 20.00 | ms/batch 174.68 | loss  6.11 | ppl   450.49\n",
      "INFO 2019-05-21 19:26:32,686: | epoch   1 |  3800/23759 batches | lr 20.00 | ms/batch 174.22 | loss  5.96 | ppl   386.64\n",
      "INFO 2019-05-21 19:27:08,519: | epoch   1 |  4000/23759 batches | lr 20.00 | ms/batch 179.16 | loss  6.05 | ppl   422.12\n",
      "INFO 2019-05-21 19:27:43,633: | epoch   1 |  4200/23759 batches | lr 20.00 | ms/batch 175.57 | loss  5.71 | ppl   302.35\n",
      "INFO 2019-05-21 19:28:18,552: | epoch   1 |  4400/23759 batches | lr 20.00 | ms/batch 174.59 | loss  5.96 | ppl   386.30\n",
      "INFO 2019-05-21 19:28:53,324: | epoch   1 |  4600/23759 batches | lr 20.00 | ms/batch 173.86 | loss  5.95 | ppl   384.61\n",
      "INFO 2019-05-21 19:29:28,445: | epoch   1 |  4800/23759 batches | lr 20.00 | ms/batch 175.60 | loss  5.80 | ppl   330.63\n",
      "INFO 2019-05-21 19:30:03,671: | epoch   1 |  5000/23759 batches | lr 20.00 | ms/batch 176.13 | loss  5.72 | ppl   305.42\n",
      "INFO 2019-05-21 19:30:38,800: | epoch   1 |  5200/23759 batches | lr 20.00 | ms/batch 175.64 | loss  5.73 | ppl   306.88\n",
      "INFO 2019-05-21 19:31:14,208: | epoch   1 |  5400/23759 batches | lr 20.00 | ms/batch 177.03 | loss  5.62 | ppl   275.59\n",
      "INFO 2019-05-21 19:31:49,900: | epoch   1 |  5600/23759 batches | lr 20.00 | ms/batch 178.46 | loss  5.74 | ppl   310.59\n",
      "INFO 2019-05-21 19:32:24,855: | epoch   1 |  5800/23759 batches | lr 20.00 | ms/batch 174.77 | loss  5.61 | ppl   273.17\n",
      "INFO 2019-05-21 19:32:59,999: | epoch   1 |  6000/23759 batches | lr 20.00 | ms/batch 175.72 | loss  5.68 | ppl   293.94\n",
      "INFO 2019-05-21 19:33:35,487: | epoch   1 |  6200/23759 batches | lr 20.00 | ms/batch 177.44 | loss  5.73 | ppl   309.26\n",
      "INFO 2019-05-21 19:34:12,511: | epoch   1 |  6400/23759 batches | lr 20.00 | ms/batch 185.12 | loss  5.56 | ppl   259.96\n",
      "INFO 2019-05-21 19:34:49,234: | epoch   1 |  6600/23759 batches | lr 20.00 | ms/batch 183.61 | loss  5.66 | ppl   285.94\n",
      "INFO 2019-05-21 19:35:25,554: | epoch   1 |  6800/23759 batches | lr 20.00 | ms/batch 181.60 | loss  5.60 | ppl   270.52\n",
      "INFO 2019-05-21 19:36:02,952: | epoch   1 |  7000/23759 batches | lr 20.00 | ms/batch 186.98 | loss  5.47 | ppl   236.59\n",
      "INFO 2019-05-21 19:36:40,344: | epoch   1 |  7200/23759 batches | lr 20.00 | ms/batch 186.96 | loss  5.34 | ppl   209.43\n",
      "INFO 2019-05-21 19:37:16,479: | epoch   1 |  7400/23759 batches | lr 20.00 | ms/batch 180.67 | loss  5.25 | ppl   189.97\n",
      "INFO 2019-05-21 19:37:51,762: | epoch   1 |  7600/23759 batches | lr 20.00 | ms/batch 176.41 | loss  5.44 | ppl   229.99\n",
      "INFO 2019-05-21 19:38:26,591: | epoch   1 |  7800/23759 batches | lr 20.00 | ms/batch 174.14 | loss  5.41 | ppl   222.73\n",
      "INFO 2019-05-21 19:39:01,482: | epoch   1 |  8000/23759 batches | lr 20.00 | ms/batch 174.45 | loss  5.46 | ppl   234.51\n",
      "INFO 2019-05-21 19:39:37,951: | epoch   1 |  8200/23759 batches | lr 20.00 | ms/batch 182.35 | loss  5.48 | ppl   239.07\n",
      "INFO 2019-05-21 19:40:14,408: | epoch   1 |  8400/23759 batches | lr 20.00 | ms/batch 182.28 | loss  5.53 | ppl   251.33\n",
      "INFO 2019-05-21 19:40:49,310: | epoch   1 |  8600/23759 batches | lr 20.00 | ms/batch 174.51 | loss  5.44 | ppl   231.24\n",
      "INFO 2019-05-21 19:41:24,173: | epoch   1 |  8800/23759 batches | lr 20.00 | ms/batch 174.31 | loss  5.39 | ppl   219.03\n",
      "INFO 2019-05-21 19:41:59,204: | epoch   1 |  9000/23759 batches | lr 20.00 | ms/batch 175.15 | loss  5.55 | ppl   256.52\n",
      "INFO 2019-05-21 19:42:34,181: | epoch   1 |  9200/23759 batches | lr 20.00 | ms/batch 174.89 | loss  5.55 | ppl   258.45\n",
      "INFO 2019-05-21 19:43:09,256: | epoch   1 |  9400/23759 batches | lr 20.00 | ms/batch 175.37 | loss  5.60 | ppl   269.91\n",
      "INFO 2019-05-21 19:43:45,421: | epoch   1 |  9600/23759 batches | lr 20.00 | ms/batch 180.82 | loss  5.55 | ppl   256.65\n",
      "INFO 2019-05-21 19:44:20,318: | epoch   1 |  9800/23759 batches | lr 20.00 | ms/batch 174.49 | loss  5.40 | ppl   220.57\n",
      "INFO 2019-05-21 19:44:55,281: | epoch   1 | 10000/23759 batches | lr 20.00 | ms/batch 174.81 | loss  5.35 | ppl   210.60\n",
      "INFO 2019-05-21 19:45:30,552: | epoch   1 | 10200/23759 batches | lr 20.00 | ms/batch 176.35 | loss  5.36 | ppl   211.88\n",
      "INFO 2019-05-21 19:46:06,436: | epoch   1 | 10400/23759 batches | lr 20.00 | ms/batch 179.42 | loss  5.23 | ppl   185.98\n",
      "INFO 2019-05-21 19:46:43,349: | epoch   1 | 10600/23759 batches | lr 20.00 | ms/batch 184.56 | loss  5.47 | ppl   237.98\n",
      "INFO 2019-05-21 19:47:18,817: | epoch   1 | 10800/23759 batches | lr 20.00 | ms/batch 177.34 | loss  5.38 | ppl   216.10\n",
      "INFO 2019-05-21 19:47:53,939: | epoch   1 | 11000/23759 batches | lr 20.00 | ms/batch 175.61 | loss  5.34 | ppl   209.53\n",
      "INFO 2019-05-21 19:48:29,170: | epoch   1 | 11200/23759 batches | lr 20.00 | ms/batch 176.15 | loss  5.40 | ppl   221.87\n",
      "INFO 2019-05-21 19:49:03,654: | epoch   1 | 11400/23759 batches | lr 20.00 | ms/batch 172.42 | loss  5.38 | ppl   216.87\n",
      "INFO 2019-05-21 19:49:38,096: | epoch   1 | 11600/23759 batches | lr 20.00 | ms/batch 172.21 | loss  5.37 | ppl   215.31\n",
      "INFO 2019-05-21 19:50:12,484: | epoch   1 | 11800/23759 batches | lr 20.00 | ms/batch 171.94 | loss  5.22 | ppl   184.69\n",
      "INFO 2019-05-21 19:50:46,988: | epoch   1 | 12000/23759 batches | lr 20.00 | ms/batch 172.52 | loss  5.22 | ppl   184.41\n",
      "INFO 2019-05-21 19:51:21,436: | epoch   1 | 12200/23759 batches | lr 20.00 | ms/batch 172.23 | loss  5.35 | ppl   211.02\n",
      "INFO 2019-05-21 19:51:55,953: | epoch   1 | 12400/23759 batches | lr 20.00 | ms/batch 172.58 | loss  5.29 | ppl   197.41\n",
      "INFO 2019-05-21 19:52:30,482: | epoch   1 | 12600/23759 batches | lr 20.00 | ms/batch 172.65 | loss  5.27 | ppl   193.49\n",
      "INFO 2019-05-21 19:53:04,995: | epoch   1 | 12800/23759 batches | lr 20.00 | ms/batch 172.56 | loss  5.34 | ppl   209.28\n",
      "INFO 2019-05-21 19:53:40,066: | epoch   1 | 13000/23759 batches | lr 20.00 | ms/batch 175.35 | loss  5.37 | ppl   215.80\n",
      "INFO 2019-05-21 19:54:14,630: | epoch   1 | 13200/23759 batches | lr 20.00 | ms/batch 172.82 | loss  5.18 | ppl   177.53\n",
      "INFO 2019-05-21 19:54:49,127: | epoch   1 | 13400/23759 batches | lr 20.00 | ms/batch 172.48 | loss  5.19 | ppl   179.63\n",
      "INFO 2019-05-21 19:55:23,492: | epoch   1 | 13600/23759 batches | lr 20.00 | ms/batch 171.82 | loss  5.29 | ppl   199.10\n",
      "INFO 2019-05-21 19:55:58,058: | epoch   1 | 13800/23759 batches | lr 20.00 | ms/batch 172.83 | loss  5.06 | ppl   157.11\n",
      "INFO 2019-05-21 19:56:32,491: | epoch   1 | 14000/23759 batches | lr 20.00 | ms/batch 172.16 | loss  5.16 | ppl   174.50\n",
      "INFO 2019-05-21 19:57:06,977: | epoch   1 | 14200/23759 batches | lr 20.00 | ms/batch 172.43 | loss  5.14 | ppl   171.36\n",
      "INFO 2019-05-21 19:57:41,484: | epoch   1 | 14400/23759 batches | lr 20.00 | ms/batch 172.54 | loss  5.24 | ppl   187.85\n",
      "INFO 2019-05-21 19:58:15,984: | epoch   1 | 14600/23759 batches | lr 20.00 | ms/batch 172.50 | loss  5.20 | ppl   181.45\n",
      "INFO 2019-05-21 19:58:50,468: | epoch   1 | 14800/23759 batches | lr 20.00 | ms/batch 172.41 | loss  5.30 | ppl   200.11\n",
      "INFO 2019-05-21 19:59:24,863: | epoch   1 | 15000/23759 batches | lr 20.00 | ms/batch 171.97 | loss  5.15 | ppl   172.41\n",
      "INFO 2019-05-21 19:59:59,380: | epoch   1 | 15200/23759 batches | lr 20.00 | ms/batch 172.58 | loss  5.28 | ppl   195.92\n",
      "INFO 2019-05-21 20:00:33,650: | epoch   1 | 15400/23759 batches | lr 20.00 | ms/batch 171.35 | loss  5.21 | ppl   182.95\n",
      "INFO 2019-05-21 20:01:08,090: | epoch   1 | 15600/23759 batches | lr 20.00 | ms/batch 172.20 | loss  5.16 | ppl   173.66\n",
      "INFO 2019-05-21 20:01:42,661: | epoch   1 | 15800/23759 batches | lr 20.00 | ms/batch 172.85 | loss  5.21 | ppl   182.28\n",
      "INFO 2019-05-21 20:02:17,017: | epoch   1 | 16000/23759 batches | lr 20.00 | ms/batch 171.78 | loss  5.00 | ppl   147.68\n",
      "INFO 2019-05-21 20:02:51,441: | epoch   1 | 16200/23759 batches | lr 20.00 | ms/batch 172.12 | loss  5.32 | ppl   205.01\n",
      "INFO 2019-05-21 20:03:25,921: | epoch   1 | 16400/23759 batches | lr 20.00 | ms/batch 172.40 | loss  5.03 | ppl   152.77\n",
      "INFO 2019-05-21 20:04:00,370: | epoch   1 | 16600/23759 batches | lr 20.00 | ms/batch 172.24 | loss  5.18 | ppl   177.41\n",
      "INFO 2019-05-21 20:04:34,881: | epoch   1 | 16800/23759 batches | lr 20.00 | ms/batch 172.55 | loss  5.20 | ppl   180.76\n",
      "INFO 2019-05-21 20:05:09,343: | epoch   1 | 17000/23759 batches | lr 20.00 | ms/batch 172.31 | loss  5.18 | ppl   178.34\n",
      "INFO 2019-05-21 20:05:43,821: | epoch   1 | 17200/23759 batches | lr 20.00 | ms/batch 172.38 | loss  5.17 | ppl   175.54\n",
      "INFO 2019-05-21 20:06:18,208: | epoch   1 | 17400/23759 batches | lr 20.00 | ms/batch 171.93 | loss  5.09 | ppl   162.09\n",
      "INFO 2019-05-21 20:06:52,606: | epoch   1 | 17600/23759 batches | lr 20.00 | ms/batch 171.99 | loss  5.08 | ppl   161.08\n",
      "INFO 2019-05-21 20:07:26,972: | epoch   1 | 17800/23759 batches | lr 20.00 | ms/batch 171.83 | loss  5.05 | ppl   156.22\n",
      "INFO 2019-05-21 20:08:01,329: | epoch   1 | 18000/23759 batches | lr 20.00 | ms/batch 171.78 | loss  5.15 | ppl   172.65\n",
      "INFO 2019-05-21 20:08:35,660: | epoch   1 | 18200/23759 batches | lr 20.00 | ms/batch 171.65 | loss  5.14 | ppl   170.02\n",
      "INFO 2019-05-21 20:09:10,048: | epoch   1 | 18400/23759 batches | lr 20.00 | ms/batch 171.94 | loss  5.26 | ppl   192.80\n",
      "INFO 2019-05-21 20:09:44,393: | epoch   1 | 18600/23759 batches | lr 20.00 | ms/batch 171.72 | loss  5.22 | ppl   184.52\n",
      "INFO 2019-05-21 20:10:18,788: | epoch   1 | 18800/23759 batches | lr 20.00 | ms/batch 171.97 | loss  5.02 | ppl   151.75\n",
      "INFO 2019-05-21 20:10:53,244: | epoch   1 | 19000/23759 batches | lr 20.00 | ms/batch 172.27 | loss  5.23 | ppl   186.12\n",
      "INFO 2019-05-21 20:11:27,591: | epoch   1 | 19200/23759 batches | lr 20.00 | ms/batch 171.74 | loss  5.08 | ppl   159.99\n",
      "INFO 2019-05-21 20:12:02,059: | epoch   1 | 19400/23759 batches | lr 20.00 | ms/batch 172.33 | loss  5.10 | ppl   163.37\n",
      "INFO 2019-05-21 20:12:36,565: | epoch   1 | 19600/23759 batches | lr 20.00 | ms/batch 172.53 | loss  4.97 | ppl   144.18\n",
      "INFO 2019-05-21 20:13:10,935: | epoch   1 | 19800/23759 batches | lr 20.00 | ms/batch 171.85 | loss  5.11 | ppl   165.41\n",
      "INFO 2019-05-21 20:13:45,368: | epoch   1 | 20000/23759 batches | lr 20.00 | ms/batch 172.16 | loss  5.18 | ppl   176.88\n",
      "INFO 2019-05-21 20:14:19,766: | epoch   1 | 20200/23759 batches | lr 20.00 | ms/batch 171.99 | loss  5.09 | ppl   162.86\n",
      "INFO 2019-05-21 20:14:54,234: | epoch   1 | 20400/23759 batches | lr 20.00 | ms/batch 172.34 | loss  5.05 | ppl   155.48\n",
      "INFO 2019-05-21 20:15:28,527: | epoch   1 | 20600/23759 batches | lr 20.00 | ms/batch 171.46 | loss  5.19 | ppl   179.10\n",
      "INFO 2019-05-21 20:16:02,889: | epoch   1 | 20800/23759 batches | lr 20.00 | ms/batch 171.81 | loss  5.04 | ppl   153.70\n",
      "INFO 2019-05-21 20:16:37,327: | epoch   1 | 21000/23759 batches | lr 20.00 | ms/batch 172.19 | loss  5.28 | ppl   195.70\n",
      "INFO 2019-05-21 20:17:11,734: | epoch   1 | 21200/23759 batches | lr 20.00 | ms/batch 172.03 | loss  5.17 | ppl   175.34\n",
      "INFO 2019-05-21 20:17:46,148: | epoch   1 | 21400/23759 batches | lr 20.00 | ms/batch 172.06 | loss  5.06 | ppl   157.47\n",
      "INFO 2019-05-21 20:18:20,565: | epoch   1 | 21600/23759 batches | lr 20.00 | ms/batch 172.08 | loss  5.12 | ppl   167.32\n",
      "INFO 2019-05-21 20:18:54,918: | epoch   1 | 21800/23759 batches | lr 20.00 | ms/batch 171.76 | loss  5.06 | ppl   158.21\n",
      "INFO 2019-05-21 20:19:29,372: | epoch   1 | 22000/23759 batches | lr 20.00 | ms/batch 172.26 | loss  5.03 | ppl   152.66\n",
      "INFO 2019-05-21 20:20:03,828: | epoch   1 | 22200/23759 batches | lr 20.00 | ms/batch 172.28 | loss  4.94 | ppl   139.44\n",
      "INFO 2019-05-21 20:20:38,343: | epoch   1 | 22400/23759 batches | lr 20.00 | ms/batch 172.57 | loss  4.97 | ppl   144.54\n",
      "INFO 2019-05-21 20:21:12,708: | epoch   1 | 22600/23759 batches | lr 20.00 | ms/batch 171.82 | loss  4.97 | ppl   143.61\n",
      "INFO 2019-05-21 20:21:47,078: | epoch   1 | 22800/23759 batches | lr 20.00 | ms/batch 171.85 | loss  5.12 | ppl   168.11\n",
      "INFO 2019-05-21 20:22:21,488: | epoch   1 | 23000/23759 batches | lr 20.00 | ms/batch 172.05 | loss  4.94 | ppl   140.41\n",
      "INFO 2019-05-21 20:22:55,896: | epoch   1 | 23200/23759 batches | lr 20.00 | ms/batch 172.04 | loss  4.98 | ppl   144.96\n",
      "INFO 2019-05-21 20:23:30,380: | epoch   1 | 23400/23759 batches | lr 20.00 | ms/batch 172.42 | loss  5.11 | ppl   166.30\n",
      "INFO 2019-05-21 20:24:04,652: | epoch   1 | 23600/23759 batches | lr 20.00 | ms/batch 171.35 | loss  5.06 | ppl   156.84\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-c2e877664640>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorpus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/media/gabrielamelo/Novo volume/Projects/portuguese_wsc/src/training.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, corpus, criterion, device)\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0mtrain_one_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorpus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m             \u001b[0mval_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorpus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'-'\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m89\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/gabrielamelo/Novo volume/Projects/portuguese_wsc/src/training.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(model, corpus, criterion, device)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0moutput_flat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mntokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m             \u001b[0mtotal_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_flat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m             \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrepackage_hidden\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtotal_loss\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered"
     ]
    }
   ],
   "source": [
    "train(model, corpus, criterion, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# timestamp = datetime.datetime.now()\n",
    "# with open(MODEL_FILE_NAME.format(timestamp), 'wb') as f:\n",
    "#     torch.save(model, f)\n",
    "\n",
    "# with open(MODEL_FILE_NAME.format(timestamp), 'rb') as f: # TODO won't be able to load, given that MODEL_FILE_NAME is dynamic\n",
    "#     model = torch.load(f)\n",
    "#     # after load the rnn params are not a continuous chunk of memory\n",
    "#     # this makes them a continuous chunk, and will speed up forward pass\n",
    "#     model.rnn.flatten_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-1df6c2ce6265>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mval_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorpus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/media/gabrielamelo/Novo volume/Projects/portuguese_wsc/src/training.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(model, corpus, criterion, device, use_test_data)\u001b[0m\n\u001b[1;32m     73\u001b[0m             \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m             \u001b[0moutput_flat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mntokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m             \u001b[0mtotal_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_flat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m             \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrepackage_hidden\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtotal_loss\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered"
     ]
    }
   ],
   "source": [
    "val_loss = evaluate(model, corpus, criterion, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wsc_port",
   "language": "python",
   "name": "wsc_port"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
