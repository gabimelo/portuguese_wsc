{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('..')\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "import torch\n",
    "\n",
    "import torch.nn as nn\n",
    "\n",
    "from src.consts import *\n",
    "from src.main import main, setup_torch, get_corpus\n",
    "from src.model import RNNModel\n",
    "from src.training import train, evaluate\n",
    "from src.split_cross_entropy_loss import SplitCrossEntropyLoss\n",
    "from src.utils import summary, check_cuda_mem, get_latest_model_file\n",
    "from src.custom_data_parallel import CustomDataParallel\n",
    "from src.parallel import DataParallelCriterion\n",
    "from src.wsc_parser import generate_df_from_json\n",
    "from src.winograd_schema_challenge import find_missing_wsc_words_in_corpus_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "setup_torch()\n",
    "main_gpu_index = 0\n",
    "device = torch.device(\"cuda:\" + str(main_gpu_index) if USE_CUDA else \"cpu\")\n",
    "corpus = get_corpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "111550"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(corpus.dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert corpus.valid.size()[0] == 11606861\n",
    "assert corpus.train.max() < len(corpus.dictionary)\n",
    "assert corpus.valid.max() < len(corpus.dictionary)\n",
    "assert corpus.test.max() < len(corpus.dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = generate_df_from_json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['chatbots',\n",
       " 'retirei',\n",
       " 'Timmy',\n",
       " 'protegemos',\n",
       " 'largá-las',\n",
       " 'acudi-lo',\n",
       " 'usei',\n",
       " 'gargalhou',\n",
       " 'reconfortou',\n",
       " 'abaixou',\n",
       " 'balançavam',\n",
       " 'constrangidos',\n",
       " 'limpado',\n",
       " 'assisti-la',\n",
       " 'removi',\n",
       " 'peixinho',\n",
       " 'alicate',\n",
       " 'acomodada',\n",
       " 'malabarista',\n",
       " 'acomodou',\n",
       " 'compassivo',\n",
       " 'malabarismos',\n",
       " 'gameboy',\n",
       " 'Huntertropic',\n",
       " 'transando',\n",
       " 'Janie',\n",
       " 'custeou',\n",
       " 'certificou-se',\n",
       " 'Laputa',\n",
       " 'willow-towered',\n",
       " 'indiscreta',\n",
       " 'Terpsichore',\n",
       " 'kate',\n",
       " 'enfiei',\n",
       " 'respondê-la',\n",
       " 'adorou',\n",
       " 'GrWQWu8JyC',\n",
       " 'respondentes',\n",
       " 'barman',\n",
       " 'pega-pega',\n",
       " 'Kamtchatka',\n",
       " 'Shatov',\n",
       " 'ingrato',\n",
       " 'entrevistaram',\n",
       " 'newsletter',\n",
       " 'muletas',\n",
       " 'beliche',\n",
       " 'Kirilov',\n",
       " 'wrestles',\n",
       " 'empático',\n",
       " 'tapinha',\n",
       " 'contou-lhe',\n",
       " 'intrometida',\n",
       " 'examplo',\n",
       " 'melancias',\n",
       " 'latir',\n",
       " 'Check',\n",
       " 'sacou',\n",
       " 'Arqueologistas',\n",
       " 'doíam',\n",
       " 'esnobes',\n",
       " 'repeti-la',\n",
       " '4:30',\n",
       " 'Alongando',\n",
       " 'tentei',\n",
       " 'carreguei',\n",
       " 'Canopy',\n",
       " 'convidou-a',\n",
       " 'treinadora',\n",
       " 'punimos',\n",
       " 'assoviando',\n",
       " 'servi',\n",
       " 'Loebner',\n",
       " 'torradeira',\n",
       " 'compreendê-la',\n",
       " 'entupido',\n",
       " 'coloquei',\n",
       " 'Yakutsk',\n",
       " 'estúpidos',\n",
       " 'apegadas',\n",
       " 'desapontada',\n",
       " 'cantarolando',\n",
       " 'Ficamos',\n",
       " 'Xenophanes',\n",
       " 'deselegante',\n",
       " 'reinvidicava',\n",
       " 'golfistas',\n",
       " 'limoeiros',\n",
       " 'transtornado',\n",
       " 'esfaqueou']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_missing_wsc_words_in_corpus_vocab(df, corpus, english=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_data_paralellization = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CustomDataParallel(\n",
      "  (model): DataParallelModel(\n",
      "    (module): RNNModel(\n",
      "      (drop): Dropout(p=0.2)\n",
      "      (encoder): Embedding(111550, 200)\n",
      "      (rnn): LSTM(200, 200, num_layers=2, dropout=0.2)\n",
      "      (decoder): Linear(in_features=200, out_features=111550, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\n",
      "model.module.encoder.weight torch.Size([111550, 200])\n",
      "model.module.rnn.weight_ih_l0 torch.Size([800, 200])\n",
      "model.module.rnn.weight_hh_l0 torch.Size([800, 200])\n",
      "model.module.rnn.bias_ih_l0 torch.Size([800])\n",
      "model.module.rnn.bias_hh_l0 torch.Size([800])\n",
      "model.module.rnn.weight_ih_l1 torch.Size([800, 200])\n",
      "model.module.rnn.weight_hh_l1 torch.Size([800, 200])\n",
      "model.module.rnn.bias_ih_l1 torch.Size([800])\n",
      "model.module.rnn.bias_hh_l1 torch.Size([800])\n",
      "model.module.decoder.weight torch.Size([111550, 200])\n",
      "model.module.decoder.bias torch.Size([111550])\n",
      "\n",
      "Total Parameters: 23,064,750\n"
     ]
    }
   ],
   "source": [
    "ntokens = len(corpus.dictionary)\n",
    "\n",
    "model = RNNModel(MODEL_TYPE, ntokens, EMBEDDINGS_SIZE, HIDDEN_UNIT_COUNT, LAYER_COUNT, DROPOUT_PROB,\n",
    "                         TIED).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "if use_data_paralellization or USE_DATA_PARALLELIZATION:\n",
    "    cuda_devices = [i for i in range(torch.cuda.device_count())]\n",
    "    device_ids = [main_gpu_index] + cuda_devices[:main_gpu_index] + cuda_devices[main_gpu_index + 1:]\n",
    "    model = CustomDataParallel(model, device_ids=device_ids)\n",
    "    criterion = DataParallelCriterion(criterion, device_ids=device_ids)\n",
    "\n",
    "optimizer = None\n",
    "\n",
    "summary(model, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO 2019-06-17 18:42:07,307: | epoch   1 |   200/ 1856 batches | lr 20.00 | ms/batch 247.55 | loss  8.51 | ppl  4967.97\n",
      "INFO 2019-06-17 18:42:55,106: | epoch   1 |   400/ 1856 batches | lr 20.00 | ms/batch 238.99 | loss  7.87 | ppl  2614.08\n",
      "INFO 2019-06-17 18:43:42,959: | epoch   1 |   600/ 1856 batches | lr 20.00 | ms/batch 239.27 | loss  7.73 | ppl  2272.82\n",
      "INFO 2019-06-17 18:44:30,961: | epoch   1 |   800/ 1856 batches | lr 20.00 | ms/batch 240.00 | loss  7.63 | ppl  2062.42\n",
      "INFO 2019-06-17 18:45:19,077: | epoch   1 |  1000/ 1856 batches | lr 20.00 | ms/batch 240.58 | loss  7.55 | ppl  1892.01\n",
      "INFO 2019-06-17 18:46:07,157: | epoch   1 |  1200/ 1856 batches | lr 20.00 | ms/batch 240.40 | loss  7.49 | ppl  1786.53\n",
      "INFO 2019-06-17 18:46:55,293: | epoch   1 |  1400/ 1856 batches | lr 20.00 | ms/batch 240.68 | loss  7.46 | ppl  1735.63\n",
      "INFO 2019-06-17 18:47:43,390: | epoch   1 |  1600/ 1856 batches | lr 20.00 | ms/batch 240.48 | loss  7.42 | ppl  1668.99\n",
      "INFO 2019-06-17 18:48:31,472: | epoch   1 |  1800/ 1856 batches | lr 20.00 | ms/batch 240.40 | loss  7.40 | ppl  1636.85\n",
      "INFO 2019-06-17 18:48:44,802: -----------------------------------------------------------------------------------------\n",
      "INFO 2019-06-17 18:48:44,802: Running eval\n",
      "INFO 2019-06-17 18:48:44,802: -----------------------------------------------------------------------------------------\n",
      "5182it [05:22, 16.37it/s]\n",
      "INFO 2019-06-17 18:54:07,073: -----------------------------------------------------------------------------------------\n",
      "INFO 2019-06-17 18:54:07,074: | end of epoch   1 | time: 769.28s | valid loss 13.57 | valid ppl 778772.77\n",
      "INFO 2019-06-17 18:54:07,074: -----------------------------------------------------------------------------------------\n",
      "INFO 2019-06-17 18:54:55,519: | epoch   2 |   200/ 1856 batches | lr 20.00 | ms/batch 240.36 | loss  7.42 | ppl  1667.96\n",
      "INFO 2019-06-17 18:55:43,535: | epoch   2 |   400/ 1856 batches | lr 20.00 | ms/batch 240.08 | loss  7.35 | ppl  1554.45\n",
      "INFO 2019-06-17 18:56:31,717: | epoch   2 |   600/ 1856 batches | lr 20.00 | ms/batch 240.91 | loss  7.34 | ppl  1541.89\n",
      "INFO 2019-06-17 18:57:19,941: | epoch   2 |   800/ 1856 batches | lr 20.00 | ms/batch 241.12 | loss  7.33 | ppl  1530.31\n",
      "INFO 2019-06-17 18:58:08,063: | epoch   2 |  1000/ 1856 batches | lr 20.00 | ms/batch 240.61 | loss  7.33 | ppl  1526.58\n",
      "INFO 2019-06-17 18:58:19,086: -----------------------------------------------------------------------------------------\n",
      "INFO 2019-06-17 18:58:19,086: Exiting from training early\n",
      "INFO 2019-06-17 18:58:19,169: -----------------------------------------------------------------------------------------\n",
      "INFO 2019-06-17 18:58:19,170: Running eval\n",
      "INFO 2019-06-17 18:58:19,170: -----------------------------------------------------------------------------------------\n",
      "6596it [06:50, 16.37it/s]\n",
      "INFO 2019-06-17 19:05:09,990: =========================================================================================\n",
      "INFO 2019-06-17 19:05:09,991: | End of training | test loss 13.70 | test ppl 892709.89\n",
      "INFO 2019-06-17 19:05:09,991: =========================================================================================\n"
     ]
    }
   ],
   "source": [
    "train(model, corpus, criterion, optimizer, device, use_data_paralellization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wsc_port",
   "language": "python",
   "name": "wsc_port"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
